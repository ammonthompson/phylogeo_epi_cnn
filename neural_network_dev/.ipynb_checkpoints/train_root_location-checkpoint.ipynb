{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae088086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sp\n",
    "import importlib as im\n",
    "import cnn_utilities as cn\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbeb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"data_files/cblv_files/training_set_0to25.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "full_labels = pd.read_csv(\"data_files/label_files/training_loc_R0_delta_migration_treelength_meanbl_set_0to25.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "phylo_comparison_data = pd.read_csv(\"data_files/phylocomp_100min.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "phylo_comparison_labels = pd.read_csv(\"data_files/phylocomp_100min_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96898047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167783, 3514)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomize data order\n",
    "randomized_idx = np.random.permutation(full_data.shape[0])\n",
    "full_data = full_data[randomized_idx,:]\n",
    "full_labels = full_labels[randomized_idx,:]\n",
    "full_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc37810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the data shape params and aux params\n",
    "num_locs = 5\n",
    "max_tips = 502\n",
    "num_test = 2000 \n",
    "num_validation = 2000  # found early stoping epoch number using 10000 validation\n",
    "num_sample = full_data.shape[0]\n",
    "\n",
    "num_tips = cn.get_num_tips(full_data)\n",
    "subsample_prop = full_data[:,(max_tips-1) * 7]\n",
    "mu = full_data[:,(max_tips - 3) * 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c22e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make labels\n",
    "labels = full_labels[0:num_sample, 0:5]\n",
    "train_labels = labels[(num_test + num_validation):,:]\n",
    "validation_labels = labels[num_test:num_test + num_validation,]\n",
    "test_labels = labels[:num_test,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ab596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up auxilliary priors and normalize; tree statistics and prior known parameter values (or ranges) \n",
    "# get num_tips and normalize\n",
    "aux_priors_treestats = np.vstack((mu, subsample_prop, num_tips, \n",
    "                                  full_labels[0:num_sample,8], \n",
    "                                  full_labels[0:num_sample,9])).transpose()\n",
    "norm_train_aux_priors_treestats, train_aux_priors_means, train_aux_priors_sd = cn.normalize(aux_priors_treestats[num_test + num_validation:,:])\n",
    "\n",
    "norm_val_aux_priors_treestats = cn.normalize(aux_priors_treestats[num_test:num_test + num_validation,], \n",
    "                                            (train_aux_priors_means, train_aux_priors_sd))\n",
    "norm_test_aux_priors_treestats = cn.normalize(aux_priors_treestats[:num_test,], \n",
    "                                            (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "norm_aux_priors_treestats = np.concatenate((norm_test_aux_priors_treestats, \n",
    "                                            norm_val_aux_priors_treestats, \n",
    "                                            norm_train_aux_priors_treestats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebb48e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163783, 499, 7) (163783, 5, 2)\n",
      "(2000, 499, 7) (2000, 5, 2)\n",
      "(2000, 499, 7) (2000, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "# dev create data tensors\n",
    "        \n",
    "full_treeLocation_tensor, full_prior_tensor = cn.create_data_tensors(data = full_data[0:num_sample,:], \n",
    "                                                                        mu = norm_aux_priors_treestats[:,0],\n",
    "                                                                        subsample_prop = norm_aux_priors_treestats[:,1],\n",
    "                                                                        num_tips = norm_aux_priors_treestats[:,2],\n",
    "                                                                        tmrca = norm_aux_priors_treestats[:,3],\n",
    "                                                                        mean_bl = norm_aux_priors_treestats[:,4],\n",
    "                                                                        num_locs = num_locs,\n",
    "                                                                        max_tips = max_tips,\n",
    "                                                                        cblv_contains_mu_rho = True)\n",
    "\n",
    "train_treeLocation_tensor, validation_treeLocation_tensor,  test_treeLocation_tensor = cn.create_train_val_test_tensors(full_treeLocation_tensor, \n",
    "                                                                                                                        num_validation, num_test)\n",
    "train_prior_tensor, validation_prior_tensor,  test_prior_tensor = cn.create_train_val_test_tensors(full_prior_tensor, \n",
    "                                                                                                   num_validation, num_test)\n",
    "\n",
    "print(train_treeLocation_tensor.shape, train_prior_tensor.shape)\n",
    "print(test_treeLocation_tensor.shape, test_prior_tensor.shape)\n",
    "print(validation_treeLocation_tensor.shape, validation_prior_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186991d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cnn_utilities' from 'C:\\\\Users\\\\ammon_work\\\\Desktop\\\\git_repos\\\\epi_geo_simulation\\\\neural_network_dev\\\\cnn_utilities.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.reload(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61e10e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=3, strides=1)`\n",
      "  \"\"\"\n",
      "C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=5, strides=1)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# multi input cnn\n",
    "input_treeLocation_tensor = Input(shape = train_treeLocation_tensor.shape[1:3])\n",
    "w1 = layers.Conv1D(64, 3, strides = 1, activation = 'relu', padding = 'same')(input_treeLocation_tensor)\n",
    "w = layers.Conv1D(64, 3, activation = 'relu', padding = 'same')(w1)\n",
    "w = layers.MaxPooling1D(pool_size = 3, stride = 1)(w)\n",
    "w = layers.Conv1D(96, 5, activation = 'relu', padding = 'same')(w)\n",
    "w = layers.MaxPooling1D(pool_size = 5, stride = 1)(w)\n",
    "w = layers.Conv1D(128, 7, activation = 'relu', padding = 'same')(w)\n",
    "w_global_avg = layers.GlobalAveragePooling1D(name = 'w')(w)\n",
    "\n",
    "# tree + geolocation dilated\n",
    "w_dilated = layers.Conv1D(64, 3, dilation_rate = 4, activation = 'relu', padding = \"same\")(w1)\n",
    "w_dilated = layers.Conv1D(96, 5, dilation_rate = 8, activation = 'relu', padding = \"same\")(w_dilated)\n",
    "w_dilated_global_avg = layers.GlobalAveragePooling1D(name = 'w_dilated_global_avg')(w_dilated)\n",
    "\n",
    "# prior known parameters and data statistics\n",
    "input_priors_tensor = Input(shape = train_prior_tensor.shape[1:3])\n",
    "priors = layers.Flatten()(input_priors_tensor)\n",
    "priors = layers.Dense(64, activation = 'relu', kernel_initializer = 'VarianceScaling', name = 'prior1')(priors)\n",
    "\n",
    "# concatenate all above -> deep fully connected network\n",
    "concatenated_wxyz = layers.Concatenate(axis = 1, name = 'all_concatenated')([w_dilated_global_avg, \n",
    "                                                                             w_global_avg,\n",
    "                                                                             priors])\n",
    "\n",
    "wxyz = layers.Dense(128, activation = 'relu', kernel_initializer = 'VarianceScaling')(concatenated_wxyz)\n",
    "wxyz = layers.Dense(64, activation = 'relu', kernel_initializer = 'VarianceScaling')(wxyz)\n",
    "wxyz = layers.Dense(32, activation = 'relu', kernel_initializer = 'VarianceScaling')(wxyz)\n",
    "output_root_loc_layers = layers.Dense(5, activation = 'softmax', name = 'root_loc_output')(wxyz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485ef10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 163783 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "163783/163783 [==============================] - 214s 1ms/step - loss: 0.4710 - acc: 0.8679 - auc_2: 0.9660 - categorical_crossentropy: 0.4686 - val_loss: 0.4827 - val_acc: 0.8665 - val_auc_2: 0.9656 - val_categorical_crossentropy: 0.4713\n",
      "Epoch 2/5\n",
      "151936/163783 [==========================>...] - ETA: 15s - loss: 0.4692 - acc: 0.8676 - auc_2: 0.9658 - categorical_crossentropy: 0.4702"
     ]
    }
   ],
   "source": [
    "# POWER MSE\n",
    "# def myLoss(y_true, y_pred):\n",
    "#     power = 2\n",
    "#     power_loss = tf.math.abs(y_true - y_pred)**power\n",
    "#     return tf.reduce_mean(power_loss, axis=-1)\n",
    "\n",
    "myLoss = \"categorical_crossentropy\"\n",
    "\n",
    "# NOTE: 'sparse_categorical_crossentropy' doesn't require one-hot encoding.  Consider for future...\n",
    "\n",
    "# instantiate MODEL\n",
    "mymodel = Model(inputs = [input_treeLocation_tensor, input_priors_tensor], \n",
    "                outputs = output_root_loc_layers)\n",
    "mymodel.compile(optimizer = 'rmsprop', \n",
    "                loss = myLoss, \n",
    "                metrics = ['acc', tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalCrossentropy()])\n",
    "history = mymodel.fit([train_treeLocation_tensor, train_prior_tensor], \n",
    "                      train_labels,\n",
    "                    epochs = 15, batch_size = 128, \n",
    "                    validation_data = ([validation_treeLocation_tensor, validation_prior_tensor], \n",
    "                                       validation_labels))\n",
    "\n",
    "\n",
    "# make history plots\n",
    "cn.make_history_plot(history)\n",
    "\n",
    "mymodel.evaluate([test_treeLocation_tensor, test_prior_tensor], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52d4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################33\n",
    "## TEST loc pred ###\n",
    "###################\n",
    "test_preds = mymodel.predict([test_treeLocation_tensor, test_prior_tensor])\n",
    "nt_nv = num_test + num_validation\n",
    "test_pred_labels = test_labels[:, 0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4f592b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3085\n",
      "tip frequency accuracy:  0.5801623420846953\n",
      "cnn prediction accuracy:  0.8051873143863959\n",
      "top tip prediction accuracy:  0.853\n",
      "top cnn prediction accuracy:  0.857\n"
     ]
    }
   ],
   "source": [
    "# how predictive are just counts without any phylo info?\n",
    "tip_loc_counts = np.zeros((test_treeLocation_tensor.shape[0],num_locs))\n",
    "tip_loc_distro = np.zeros((test_treeLocation_tensor.shape[0],num_locs))\n",
    "accuracy_tipfreq = np.zeros((test_treeLocation_tensor.shape[0]))\n",
    "accuracy_pred = np.zeros((test_treeLocation_tensor.shape[0]))\n",
    "acc_top_pred = np.zeros((test_treeLocation_tensor.shape[0]))\n",
    "acc_top_tipfreq = np.zeros((test_treeLocation_tensor.shape[0]))\n",
    "\n",
    "for i in range(0, test_treeLocation_tensor.shape[0]):    \n",
    "    tip_loc_counts[i,:] = sum(test_treeLocation_tensor[i,:,2:2+num_locs])\n",
    "    tip_loc_distro[i,:] = tip_loc_counts[i,:] / sum(tip_loc_counts[i,:])\n",
    "    accuracy_tipfreq[i] = sum(tip_loc_distro[i,:] * test_labels[i,:])\n",
    "    accuracy_pred[i] = sum(test_preds[i,:] * test_labels[i,:])\n",
    "    acc_top_tipfreq[i] = 1 * (np.argmax(tip_loc_distro[i,:]) == np.argmax(test_labels[i,:]))\n",
    "    acc_top_pred[i] = 1 * (np.argmax(test_preds[i,:]) == np.argmax(test_labels[i,:]))\n",
    "\n",
    "print(\"tip frequency accuracy: \", np.mean(accuracy_tipfreq))\n",
    "print(\"cnn prediction accuracy: \", np.mean(accuracy_pred))\n",
    "print(\"top tip prediction accuracy: \", np.mean(acc_top_tipfreq))\n",
    "print(\"top cnn prediction accuracy: \", np.mean(acc_top_pred))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b3672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-89fe622241d4>\", line 4, in <module>\n",
      "    plt.hist(accuracy_tipfreq, bins = 20, range = [0,1])\n",
      "NameError: name 'accuracy_tipfreq' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-89fe622241d4>\", line 4, in <module>\n",
      "    plt.hist(accuracy_tipfreq, bins = 20, range = [0,1])\n",
      "NameError: name 'accuracy_tipfreq' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-89fe622241d4>\", line 4, in <module>\n",
      "    plt.hist(accuracy_tipfreq, bins = 20, range = [0,1])\n",
      "NameError: name 'accuracy_tipfreq' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = np.max(test_preds * test_labels, axis = 1)\n",
    "plt.hist(test_accuracy, bins = 20, range = [0,1])\n",
    "plt.show()\n",
    "plt.hist(accuracy_tipfreq, bins = 20, range = [0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfd58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "mymodel.save(\"saved_models/train_128batch_10epoch_root_location.hdf5\")\n",
    "# mymodel.save(\"saved_models/train_largerRange_128batch_10epoch_root_location.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
