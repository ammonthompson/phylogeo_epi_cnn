{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c44607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import io\n",
    "from io import StringIO\n",
    "import re\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "from keras import models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as sp\n",
    "from scipy.stats import kde\n",
    "import importlib as im\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "\n",
    "# my utilities\n",
    "import cnn_utilities as cn\n",
    "import uq_utilities_2 as uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b94ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model and normalization values\n",
    "my_model = models.load_model(\"../saved_models/train_extant_R0_sampleRate_migrationRate.hdf5\")\n",
    "\n",
    "mean_sd = pd.read_csv(\"../saved_models/train_extant_normalization_label_mean_sd.csv\", \n",
    "                     index_col = 0).to_numpy()\n",
    "\n",
    "train_means = mean_sd[0,:]\n",
    "train_sd = mean_sd[1,:]\n",
    "train_aux_priors_means = train_means[3:,]\n",
    "train_aux_priors_sd = train_sd[3:,]\n",
    "\n",
    "num_locs = 5\n",
    "max_tips = 502\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acbb3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation data\n",
    "extant_data = pd.read_csv(\"../data_files/extant_training_set_0to40.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_training_set_0to40_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1de2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_data_mu_ntips = pd.read_table(\"data_files/labels_and_preds/extant_training_set_0to40_param_values_numtips_propsamp.txt\", \n",
    "                                  header = 0).to_numpy()\n",
    "extant_data_mu_ntips = np.column_stack((extant_data_mu_ntips[:,0], extant_data_mu_ntips[:,1]/extant_data_mu_ntips[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e77cf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111157, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extant_data_mu_ntips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42957377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "# compute and gather auxilliary prior data ##\n",
    "##############################################\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "phylocomp_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((phylocomp_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "# PREDICT R0, sample rate, migration rate\n",
    "extant_normalized_preds = my_model.predict([extant_treeLocation_tensor, extant_prior_tensor])\n",
    "\n",
    "# reversing normalization\n",
    "cnn_extant_preds = cn.denormalize(extant_normalized_preds, train_means[0:3], train_sd[0:3])\n",
    "log_preds = cnn_extant_preds\n",
    "cnn_extant_preds = np.exp(cnn_extant_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af05e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ checking coverage #################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90892626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 is done.   time = 1008.4092178344727\n",
      "0.1 is done.   time = 981.1449837684631\n",
      "0.25 is done.   time = 899.2008669376373\n",
      "0.5 is done.   time = 834.4571928977966\n",
      "0.75 is done.   time = 630.3069212436676\n",
      "0.9 is done.   time = 587.0295350551605\n",
      "0.95 is done.   time = 656.3214592933655\n"
     ]
    }
   ],
   "source": [
    "im.reload(uq)\n",
    "# make dictionaries containing interval estimating functions\n",
    "# the keys should be the quantile number\n",
    "# the values should be (lower_q_fun, upper_q_fun)\n",
    "train_dat = np.column_stack((log_preds[:,0:3], extant_data_mu_ntips))\n",
    "\n",
    "nn = 55000 #log_preds.shape[0]\n",
    "\n",
    "train_R0_cpi_fun = {}\n",
    "train_delta_cpi_fun = {}\n",
    "train_m_cpi_fun = {}\n",
    "\n",
    "inner_q = [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]\n",
    "# inner_q = [0.95]\n",
    "for q in inner_q:\n",
    "    start_time = time.time()\n",
    "\n",
    "    m, lower_q, upper_q = uq.get_CPI(train_dat[0:nn,[0,3,4]],\n",
    "                                                   np.log(extant_labels[0:nn,5]), \n",
    "                                                   frac=0.05, inner_quantile=q)\n",
    "    train_R0_cpi_fun[q] = (lower_q, upper_q)\n",
    "    \n",
    "    m, lower_q, upper_q = uq.get_CPI(train_dat[0:nn,[1,3,4]],\n",
    "                                               np.log(extant_labels[0:nn,6]), \n",
    "                                               frac=0.05, inner_quantile=q)\n",
    "    train_delta_cpi_fun[q] = (lower_q, upper_q)\n",
    "    \n",
    "    m, lower_q, upper_q = uq.get_CPI(train_dat[0:nn,[2,3,4]],\n",
    "                                               np.log(extant_labels[0:nn,7]), \n",
    "                                               frac=0.05, inner_quantile=q)\n",
    "    train_m_cpi_fun[q] = (lower_q, upper_q)\n",
    "    \n",
    "    print(str(q) + \" is done.   time = \" + str(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f69ba049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data set\n",
    "uq_cal_data = pd.read_csv(\"data_files/labels_and_preds/uq_calibration_sets_0to20.cblv.csv\",\n",
    "                            header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "uq_cal_labels = pd.read_table(\"data_files/labels_and_preds/uq_calibration_sets_0to20_labels.tsv\", header = 0).to_numpy()\n",
    "uq_cal_mutips = pd.read_table(\"data_files/labels_and_preds/uq_calibration_sets_0to20_numtips_propsamp.txt\", header = 0).to_numpy()\n",
    "uq_cal_mutips = np.column_stack((uq_cal_mutips[:,0], uq_cal_mutips[:,1]/uq_cal_mutips[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9512d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "uq_cal_subsample_prop = uq_cal_data[:,(max_tips-1) * 7]\n",
    "uq_cal_mu = uq_cal_data[:,(max_tips - 3) * 7]\n",
    "uq_cal_num_tips = cn.get_num_tips(uq_cal_data)\n",
    "\n",
    "aux_uq_cal = np.vstack((uq_cal_mu, uq_cal_subsample_prop, uq_cal_num_tips,\n",
    "                          uq_cal_labels[:,8], uq_cal_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_uq_cal = cn.normalize(aux_uq_cal, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "# create input tensors\n",
    "aux_uq_cal_treeLocation_tensor, aux_uq_cal_prior_tensor = cn.create_data_tensors(data = uq_cal_data, \n",
    "                                                                                    mu = norm_aux_uq_cal[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_uq_cal[:,1],\n",
    "                                                                                    num_tips = norm_aux_uq_cal[:,2],\n",
    "                                                                                    tmrca = norm_aux_uq_cal[:,3],\n",
    "                                                                                    mean_bl = norm_aux_uq_cal[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "# PREDICT R0, sample rate, migration rate\n",
    "uq_cal_normalized_preds = my_model.predict([aux_uq_cal_treeLocation_tensor, aux_uq_cal_prior_tensor])\n",
    "\n",
    "# reversing normalization\n",
    "cnn_uq_cal_preds = cn.denormalize(uq_cal_normalized_preds, train_means[0:3], train_sd[0:3])\n",
    "cnn_uq_cal_log_preds = np.column_stack((cnn_uq_cal_preds, uq_cal_mutips))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a21a941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split calibration prediction dat for conformal prediction interval estimation and validation\n",
    "uq_num_val = 1000\n",
    "\n",
    "# for measuring resulting coverage\n",
    "cal_val_preds = cnn_uq_cal_log_preds[0:uq_num_val,:]\n",
    "cal_val_labels = uq_cal_labels[0:uq_num_val,:]\n",
    "\n",
    "# for creating UQ\n",
    "cal_preds = cnn_uq_cal_log_preds[uq_num_val:,:]\n",
    "cal_labels = uq_cal_labels[uq_num_val:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c3387a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'uq_utilities_2' from 'C:\\\\Users\\\\ammon_work\\\\Desktop\\\\RESEARCH_PROJECTS\\\\phylogeo_epi_cnn\\\\neural_network_dev\\\\uq_and_adequacy\\\\uq_utilities_2.py'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.reload(uq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7667e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 is done.   time = 1428.0229935646057\n",
      "0.1 is done.   time = 1383.3741183280945\n"
     ]
    }
   ],
   "source": [
    "# make dictionaries containing interval estimating functions\n",
    "# the keys should be the quantile number\n",
    "# the values should be (lower_q_fun, upper_q_fun)\n",
    "\n",
    "nn = cal_preds.shape[0]\n",
    "\n",
    "R0_cpi_fun = {}\n",
    "delta_cpi_fun = {}\n",
    "m_cpi_fun = {}\n",
    "\n",
    "inner_q = [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]\n",
    "# inner_q = [0.95]\n",
    "for q in inner_q:\n",
    "    start_time = time.time()\n",
    "\n",
    "    m, lower_q, upper_q = uq.get_CPI(cal_preds[0:nn,[0,3,4]],\n",
    "                                                   np.log(cal_labels[0:nn,0]), \n",
    "                                                   frac=0.01, inner_quantile=q)\n",
    "    R0_cpi_fun[q] = (lower_q, upper_q)\n",
    "    \n",
    "    m, lower_q, upper_q = uq.get_CPI(cal_preds[0:nn,[1,3,4]],\n",
    "                                               np.log(cal_labels[0:nn,1]), \n",
    "                                               frac=0.01, inner_quantile=q)\n",
    "    delta_cpi_fun[q] = (lower_q, upper_q)\n",
    "    \n",
    "    m, lower_q, upper_q = uq.get_CPI(cal_preds[0:nn,[2,3,4]],\n",
    "                                               np.log(cal_labels[0:nn,2]), \n",
    "                                               frac=0.01, inner_quantile=q)\n",
    "    m_cpi_fun[q] = (lower_q, upper_q)\n",
    "    \n",
    "    print(str(q) + \" is done.   time = \" + str(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6d8f19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 6.1\n",
      "0.1 finished: 10.9\n",
      "0.25 finished: 26.0\n",
      "0.5 finished: 49.4\n",
      "0.75 finished: 74.5\n",
      "0.9 finished: 89.60000000000001\n",
      "0.95 finished: 93.7\n",
      "0.05 finished: 4.7\n",
      "0.1 finished: 9.8\n",
      "0.25 finished: 25.4\n",
      "0.5 finished: 47.099999999999994\n",
      "0.75 finished: 71.89999999999999\n",
      "0.9 finished: 88.5\n",
      "0.95 finished: 93.2\n",
      "0.05 finished: 5.2\n",
      "0.1 finished: 9.700000000000001\n",
      "0.25 finished: 23.0\n",
      "0.5 finished: 50.3\n",
      "0.75 finished: 74.1\n",
      "0.9 finished: 89.5\n",
      "0.95 finished: 93.8\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "uq_cal_R0_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cal_val_preds[:,[i,3,4]], cal_val_labels[:,i], q_fun = R0_cpi_fun)\n",
    "i=1\n",
    "uq_cal_delta_coverage = uq.make_coverage_set(None, None,  \n",
    "                                   cal_val_preds[:,[i,3,4]], cal_val_labels[:,i], q_fun = delta_cpi_fun)\n",
    "i=2\n",
    "uq_cal_m_coverage = uq.make_coverage_set(None, None,  \n",
    "                                   cal_val_preds[:,[i,3,4]], cal_val_labels[:,i], q_fun = m_cpi_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67345538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "df_caltest_coverage = pd.DataFrame(np.transpose(np.vstack((uq_cal_R0_coverage, uq_cal_delta_coverage, uq_cal_m_coverage))), \n",
    "                                            columns = [\"R0\", \"sample_rate\", \"migration_rate\"], \n",
    "                               index = [\"5\", \"10\", \"25\", \"50\", \"75\", \"90\", \"95\"])\n",
    "df_caltest_coverage.to_csv('../data_files/caltest_coverage.tsv', sep = \"\\t\", index = True)\n",
    "\n",
    "# write 95% quantiles to file\n",
    "caltest_R0_95_q = np.array([R0_cpi_fun[0.95][0](cal_val_preds[:,[0,3,4]]), R0_cpi_fun[0.95][1](cal_val_preds[:,[0,3,4]])]).transpose()\n",
    "caltest_delta_95_q = np.array([delta_cpi_fun[0.95][0](cal_val_preds[:,[1,3,4]]), delta_cpi_fun[0.95][1](cal_val_preds[:,[1,3,4]])]).transpose()\n",
    "caltest_m_95_q = np.array([m_cpi_fun[0.95][0](cal_val_preds[:,[2,3,4]]), m_cpi_fun[0.95][1](cal_val_preds[:,[2,3,4]])]).transpose()\n",
    "\n",
    "df_caltest_95q = pd.DataFrame(np.hstack((caltest_R0_95_q, caltest_delta_95_q, caltest_m_95_q)),\n",
    "                         columns = [\"R0_lq\", \"R0_uq\", \"delta_lq\", \"delta_uq\", \"m_lq\", \"m_uq\"])\n",
    "df_caltest_95q.to_csv('output/caltest_95q.tsv', sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4034697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 7.246376811594203\n",
      "0.1 finished: 12.318840579710146\n",
      "0.25 finished: 28.26086956521739\n",
      "0.5 finished: 54.347826086956516\n",
      "0.75 finished: 79.71014492753623\n",
      "0.9 finished: 92.02898550724638\n",
      "0.95 finished: 96.37681159420289\n",
      "0.05 finished: 3.6231884057971016\n",
      "0.1 finished: 7.971014492753622\n",
      "0.25 finished: 30.434782608695656\n",
      "0.5 finished: 55.79710144927537\n",
      "0.75 finished: 73.91304347826086\n",
      "0.9 finished: 90.57971014492753\n",
      "0.95 finished: 94.20289855072464\n",
      "0.05 finished: 5.072463768115942\n",
      "0.1 finished: 11.594202898550725\n",
      "0.25 finished: 24.637681159420293\n",
      "0.5 finished: 48.55072463768116\n",
      "0.75 finished: 71.73913043478261\n",
      "0.9 finished: 90.57971014492753\n",
      "0.95 finished: 94.92753623188406\n"
     ]
    }
   ],
   "source": [
    "# coverage experiment 0 (true model dataset)\n",
    "im.reload(uq)\n",
    "\n",
    "### coverage of CI for test dataset\n",
    "cnn_phylocomp_preds = pd.read_table(\"data_files/labels_and_preds/extant_cnn_preds.tsv\", header = 0).to_numpy()\n",
    "cnn_phylocomp_labels = pd.read_table(\"data_files/labels_and_preds/extant_labels.tsv\", header = 0).to_numpy()\n",
    "cnn_phylocomp_mutips = pd.read_table(\"data_files/labels_and_preds/extant_phylocomp_param_values_numtips_propsamp.txt\", header = 0).to_numpy()\n",
    "\n",
    "cnn_phylocomp_preds = np.column_stack((np.log(cnn_phylocomp_preds[:,0:3]), cnn_phylocomp_mutips[:,0], cnn_phylocomp_mutips[:,1]/cnn_phylocomp_mutips[:,2]))\n",
    "\n",
    "# phylocomp true model\n",
    "\n",
    "# compute coverages\n",
    "i=0\n",
    "R0_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_phylocomp_preds[:,[i,3,4]], cnn_phylocomp_labels[:,i], q_fun = train_R0_cpi_fun)\n",
    "i=1\n",
    "delta_coverage = uq.make_coverage_set(None, None,  \n",
    "                                   cnn_phylocomp_preds[:,[i,3,4]], cnn_phylocomp_labels[:,i], q_fun = train_delta_cpi_fun)\n",
    "i=2\n",
    "m_coverage = uq.make_coverage_set(None, None,  \n",
    "                                   cnn_phylocomp_preds[:,[i,3,4]], cnn_phylocomp_labels[:,i], q_fun = train_m_cpi_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d2344041",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 6.521739130434782\n",
      "0.1 finished: 10.144927536231885\n",
      "0.25 finished: 27.536231884057973\n",
      "0.5 finished: 55.79710144927537\n",
      "0.75 finished: 79.71014492753623\n",
      "0.9 finished: 92.02898550724638\n",
      "0.95 finished: 96.37681159420289\n",
      "0.05 finished: 2.898550724637681\n",
      "0.1 finished: 9.420289855072465\n",
      "0.25 finished: 30.434782608695656\n",
      "0.5 finished: 55.072463768115945\n",
      "0.75 finished: 73.91304347826086\n",
      "0.9 finished: 88.40579710144928\n",
      "0.95 finished: 94.20289855072464\n",
      "0.05 finished: 5.797101449275362\n",
      "0.1 finished: 10.869565217391305\n",
      "0.25 finished: 24.637681159420293\n",
      "0.5 finished: 49.275362318840585\n",
      "0.75 finished: 70.28985507246377\n",
      "0.9 finished: 89.85507246376811\n",
      "0.95 finished: 94.92753623188406\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3571\n"
     ]
    }
   ],
   "source": [
    "# write to file\n",
    "df_cnn_coverage = pd.DataFrame(np.transpose(np.vstack((R0_coverage, delta_coverage, m_coverage))), \n",
    "                                            columns = [\"R0\", \"sample_rate\", \"migration_rate\"], \n",
    "                               index = [\"5\", \"10\", \"25\", \"50\", \"75\", \"90\", \"95\"])\n",
    "df_cnn_coverage.to_csv('../data_files/cnn_coverage.tsv', sep = \"\\t\", index = True)\n",
    "\n",
    "# write 95% quantiles to file\n",
    "phylocomp_R0_95_q = np.array([R0_cpi_fun[0.95][0](cnn_phylocomp_preds[:,[0,3,4]]), R0_cpi_fun[0.95][1](cnn_phylocomp_preds[:,[0,3,4]])]).transpose()\n",
    "phylocomp_delta_95_q = np.array([delta_cpi_fun[0.95][0](cnn_phylocomp_preds[:,[1,3,4]]), delta_cpi_fun[0.95][1](cnn_phylocomp_preds[:,[1,3,4]])]).transpose()\n",
    "phylocomp_m_95_q = np.array([m_cpi_fun[0.95][0](cnn_phylocomp_preds[:,[2,3,4]]), m_cpi_fun[0.95][1](cnn_phylocomp_preds[:,[2,3,4]])]).transpose()\n",
    "\n",
    "df_cnn_95q = pd.DataFrame(np.hstack((phylocomp_R0_95_q, phylocomp_delta_95_q, phylocomp_m_95_q)),\n",
    "                         columns = [\"R0_lq\", \"R0_uq\", \"delta_lq\", \"delta_uq\", \"m_lq\", \"m_uq\"])\n",
    "df_cnn_95q.to_csv('output/phylocomp_cnn_95q.tsv', sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ba667542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure coverage of predictions on out-of-model test data (misspecified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca1883c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 0.0\n",
      "0.1 finished: 0.0\n",
      "0.25 finished: 1.0752688172043012\n",
      "0.5 finished: 7.526881720430108\n",
      "0.75 finished: 17.20430107526882\n",
      "0.9 finished: 30.107526881720432\n",
      "0.95 finished: 41.935483870967744\n",
      "0.05 finished: 5.376344086021505\n",
      "0.1 finished: 9.67741935483871\n",
      "0.25 finished: 25.806451612903224\n",
      "0.5 finished: 43.01075268817204\n",
      "0.75 finished: 72.04301075268818\n",
      "0.9 finished: 82.79569892473118\n",
      "0.95 finished: 90.32258064516128\n",
      "0.05 finished: 2.1505376344086025\n",
      "0.1 finished: 7.526881720430108\n",
      "0.25 finished: 12.903225806451612\n",
      "0.5 finished: 25.806451612903224\n",
      "0.75 finished: 50.53763440860215\n",
      "0.9 finished: 75.26881720430107\n",
      "0.95 finished: 79.56989247311827\n"
     ]
    }
   ],
   "source": [
    "# make coverage sets for R0 misspecification experiments\n",
    "cnn_miss_r0_preds = pd.read_table(\"../output/misspec_R0_cnn_preds.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_r0_labels = pd.read_table(\"../output/misspec_R0_labels.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_r0_mutips = pd.read_table(\"data_files/labels_and_preds/extant_misspec_R0_param_values_numtips_propsamp.txt\", \n",
    "                                     header = 0).to_numpy()\n",
    "\n",
    "cnn_miss_r0_preds = np.column_stack((np.log(cnn_miss_r0_preds[:,0:3]), cnn_miss_r0_mutips[:,0], \n",
    "                                       cnn_miss_r0_mutips[:,1]/cnn_miss_r0_mutips[:,2]))\n",
    "\n",
    "\n",
    "i=0\n",
    "missR0_R0_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_r0_preds[:,[i,3,4]], cnn_miss_r0_labels[:,i], q_fun = R0_cpi_fun)\n",
    "i=1\n",
    "missR0_delta_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_r0_preds[:,[i,3,4]], cnn_miss_r0_labels[:,i], q_fun = delta_cpi_fun)\n",
    "i=2\n",
    "missR0_m_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_r0_preds[:,[i,3,4]], cnn_miss_r0_labels[:,i], q_fun = m_cpi_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "948a1975",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 0.0\n",
      "0.1 finished: 0.0\n",
      "0.25 finished: 1.0752688172043012\n",
      "0.5 finished: 7.526881720430108\n",
      "0.75 finished: 15.053763440860216\n",
      "0.9 finished: 24.731182795698924\n",
      "0.95 finished: 35.483870967741936\n",
      "0.05 finished: 5.376344086021505\n",
      "0.1 finished: 6.451612903225806\n",
      "0.25 finished: 22.58064516129032\n",
      "0.5 finished: 37.634408602150536\n",
      "0.75 finished: 65.59139784946237\n",
      "0.9 finished: 80.64516129032258\n",
      "0.95 finished: 87.09677419354838\n",
      "0.05 finished: 2.1505376344086025\n",
      "0.1 finished: 5.376344086021505\n",
      "0.25 finished: 12.903225806451612\n",
      "0.5 finished: 23.655913978494624\n",
      "0.75 finished: 45.16129032258064\n",
      "0.9 finished: 61.29032258064516\n",
      "0.95 finished: 73.11827956989248\n"
     ]
    }
   ],
   "source": [
    "df_missR0_cnn_coverage = pd.DataFrame(np.transpose(np.vstack((missR0_R0_coverage, missR0_delta_coverage, missR0_m_coverage))), \n",
    "                                            columns = [\"R0\", \"sample_rate\", \"migration_rate\"], \n",
    "                               index = [\"5\", \"10\", \"25\", \"50\", \"75\", \"90\", \"95\"])\n",
    "df_missR0_cnn_coverage.to_csv('../data_files/missR0_cnn_coverage.tsv', sep = \"\\t\", index = True)\n",
    "\n",
    "# write 95% quantiles to file\n",
    "missR0_R0_95_q = np.array([R0_cpi_fun[0.95][0](cnn_miss_r0_preds[:,[0,3,4]]), R0_cpi_fun[0.95][1](cnn_miss_r0_preds[:,[0,3,4]])]).transpose()\n",
    "missR0_delta_95_q = np.array([delta_cpi_fun[0.95][0](cnn_miss_r0_preds[:,[1,3,4]]), delta_cpi_fun[0.95][1](cnn_miss_r0_preds[:,[1,3,4]])]).transpose()\n",
    "missR0_m_95_q = np.array([m_cpi_fun[0.95][0](cnn_miss_r0_preds[:,[2,3,4]]), m_cpi_fun[0.95][1](cnn_miss_r0_preds[:,[2,3,4]])]).transpose()\n",
    "\n",
    "df_cnn_95q = pd.DataFrame(np.hstack((missR0_R0_95_q, missR0_delta_95_q, missR0_m_95_q)),\n",
    "                         columns = [\"R0_lq\", \"R0_uq\", \"delta_lq\", \"delta_uq\", \"m_lq\", \"m_uq\"])\n",
    "df_cnn_95q.to_csv('output/missR0_cnn_95q.tsv', sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e6076417",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 8.47457627118644\n",
      "0.1 finished: 12.711864406779661\n",
      "0.25 finished: 28.8135593220339\n",
      "0.5 finished: 44.06779661016949\n",
      "0.75 finished: 64.40677966101694\n",
      "0.9 finished: 83.05084745762711\n",
      "0.95 finished: 89.83050847457628\n",
      "0.05 finished: 0.0\n",
      "0.1 finished: 0.847457627118644\n",
      "0.25 finished: 5.932203389830509\n",
      "0.5 finished: 23.728813559322035\n",
      "0.75 finished: 39.83050847457627\n",
      "0.9 finished: 50.847457627118644\n",
      "0.95 finished: 61.016949152542374\n",
      "0.05 finished: 3.389830508474576\n",
      "0.1 finished: 5.084745762711865\n",
      "0.25 finished: 12.711864406779661\n",
      "0.5 finished: 32.20338983050847\n",
      "0.75 finished: 48.30508474576271\n",
      "0.9 finished: 67.79661016949152\n",
      "0.95 finished: 77.96610169491525\n"
     ]
    }
   ],
   "source": [
    "# make coverage sets for delta misspecification experiments\n",
    "\n",
    "cnn_miss_delta_preds = pd.read_table(\"../output/misspec_delta_cnn_preds.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_delta_labels = pd.read_table(\"../output/misspec_delta_labels.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_delta_mutips = pd.read_table(\"data_files/labels_and_preds/extant_misspec_delta_param_values_numtips_propsamp.txt\", \n",
    "                                     header = 0).to_numpy()\n",
    "\n",
    "cnn_miss_delta_preds = np.column_stack((np.log(cnn_miss_delta_preds[:,0:3]), cnn_miss_delta_mutips[:,0], \n",
    "                                       cnn_miss_delta_mutips[:,1]/cnn_miss_delta_mutips[:,2]))\n",
    "\n",
    "i=0\n",
    "missDelta_R0_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_delta_preds[:,[i,3,4]], cnn_miss_delta_labels[:,i], q_fun = R0_cpi_fun)\n",
    "i=1\n",
    "missDelta_delta_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_delta_preds[:,[i,3,4]], cnn_miss_delta_labels[:,i], q_fun = delta_cpi_fun)\n",
    "i=2\n",
    "missDelta_m_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_delta_preds[:,[i,3,4]], cnn_miss_delta_labels[:,i], q_fun = m_cpi_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "45e47361",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 8.47457627118644\n",
      "0.1 finished: 12.711864406779661\n",
      "0.25 finished: 28.8135593220339\n",
      "0.5 finished: 44.06779661016949\n",
      "0.75 finished: 64.40677966101694\n",
      "0.9 finished: 82.20338983050848\n",
      "0.95 finished: 88.98305084745762\n",
      "0.05 finished: 0.0\n",
      "0.1 finished: 0.847457627118644\n",
      "0.25 finished: 5.084745762711865\n",
      "0.5 finished: 23.728813559322035\n",
      "0.75 finished: 39.83050847457627\n",
      "0.9 finished: 50.847457627118644\n",
      "0.95 finished: 60.16949152542372\n",
      "0.05 finished: 3.389830508474576\n",
      "0.1 finished: 5.084745762711865\n",
      "0.25 finished: 12.711864406779661\n",
      "0.5 finished: 32.20338983050847\n",
      "0.75 finished: 49.152542372881356\n",
      "0.9 finished: 66.94915254237289\n",
      "0.95 finished: 77.96610169491525\n"
     ]
    }
   ],
   "source": [
    "df_missDelta_missR0_cnn_coverage = pd.DataFrame(np.transpose(np.vstack((missDelta_R0_coverage, missDelta_delta_coverage, missDelta_m_coverage))), \n",
    "                                            columns = [\"R0\", \"sample_rate\", \"migration_rate\"], \n",
    "                               index = [\"5\", \"10\", \"25\", \"50\", \"75\", \"90\", \"95\"])\n",
    "df_missDelta_missR0_cnn_coverage.to_csv('../data_files/missDelta_cnn_coverage.tsv', sep = \"\\t\", index = True)\n",
    "\n",
    "# write 95% quantiles to file\n",
    "missDeltaR0_95_q = np.array([R0_cpi_fun[0.95][0](cnn_miss_delta_preds[:,[0,3,4]]), R0_cpi_fun[0.95][1](cnn_miss_delta_preds[:,[0,3,4]])]).transpose()\n",
    "missDeltadelta_95_q = np.array([delta_cpi_fun[0.95][0](cnn_miss_delta_preds[:,[1,3,4]]), delta_cpi_fun[0.95][1](cnn_miss_delta_preds[:,[1,3,4]])]).transpose()\n",
    "missDeltam_95_q = np.array([m_cpi_fun[0.95][0](cnn_miss_delta_preds[:,[2,3,4]]), m_cpi_fun[0.95][1](cnn_miss_delta_preds[:,[2,3,4]])]).transpose()\n",
    "\n",
    "df_cnn_95q = pd.DataFrame(np.hstack((missDeltaR0_95_q, missDeltadelta_95_q, missDeltam_95_q)),\n",
    "                         columns = [\"R0_lq\", \"R0_uq\", \"delta_lq\", \"delta_uq\", \"m_lq\", \"m_uq\"])\n",
    "df_cnn_95q.to_csv('output/missDeltacnn_95q.tsv', sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make coverage sets for m misspecification experiments\n",
    "cnn_miss_m_preds = pd.read_table(\"../output/misspec_migration_cnn_preds.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_m_labels = pd.read_table(\"../output/misspec_migration_labels.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_m_mutips = pd.read_table(\"data_files/labels_and_preds/extant_misspec_m_param_values_numtips_propsamp.txt\", \n",
    "                                     header = 0).to_numpy()\n",
    "\n",
    "cnn_miss_m_preds = np.column_stack((np.log(cnn_miss_m_preds[:,0:3]), cnn_miss_m_mutips[:,0], \n",
    "                                       cnn_miss_m_mutips[:,1]/cnn_miss_m_mutips[:,2]))\n",
    "\n",
    "i=0\n",
    "missM_R0_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_m_preds[:,[i,3,4]], cnn_miss_m_labels[:,i], q_fun = R0_cpi_fun)\n",
    "i=1\n",
    "missM_delta_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_m_preds[:,[i,3,4]], cnn_miss_m_labels[:,i], q_fun = delta_cpi_fun)\n",
    "i=2\n",
    "missM_m_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_m_preds[:,[i,3,4]], cnn_miss_m_labels[:,i], q_fun = m_cpi_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1d954d3a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 3.3333333333333335\n",
      "0.1 finished: 8.88888888888889\n",
      "0.25 finished: 27.77777777777778\n",
      "0.5 finished: 48.888888888888886\n",
      "0.75 finished: 73.33333333333333\n",
      "0.9 finished: 90.0\n",
      "0.95 finished: 94.44444444444444\n",
      "0.05 finished: 3.3333333333333335\n",
      "0.1 finished: 10.0\n",
      "0.25 finished: 23.333333333333332\n",
      "0.5 finished: 47.77777777777778\n",
      "0.75 finished: 67.77777777777779\n",
      "0.9 finished: 92.22222222222223\n",
      "0.95 finished: 96.66666666666667\n",
      "0.05 finished: 4.444444444444445\n",
      "0.1 finished: 7.777777777777778\n",
      "0.25 finished: 15.555555555555555\n",
      "0.5 finished: 27.77777777777778\n",
      "0.75 finished: 54.44444444444444\n",
      "0.9 finished: 66.66666666666666\n",
      "0.95 finished: 74.44444444444444\n"
     ]
    }
   ],
   "source": [
    "df_missM_missR0_cnn_coverage = pd.DataFrame(np.transpose(np.vstack((missM_R0_coverage, missM_delta_coverage, missM_m_coverage))), \n",
    "                                            columns = [\"R0\", \"sample_rate\", \"migration_rate\"], \n",
    "                               index = [\"5\", \"10\", \"25\", \"50\", \"75\", \"90\", \"95\"])\n",
    "df_missM_missR0_cnn_coverage.to_csv('../data_files/missM_cnn_coverage.tsv', sep = \"\\t\", index = True)\n",
    "\n",
    "# write 95% quantiles to file\n",
    "missM_R0_95_q = np.array([R0_cpi_fun[0.95][0](cnn_miss_m_preds[:,[0,3,4]]), R0_cpi_fun[0.95][1](cnn_miss_m_preds[:,[0,3,4]])]).transpose()\n",
    "missM_delta_95_q = np.array([delta_cpi_fun[0.95][0](cnn_miss_m_preds[:,[1,3,4]]), delta_cpi_fun[0.95][1](cnn_miss_m_preds[:,[1,3,4]])]).transpose()\n",
    "missM_m_95_q = np.array([m_cpi_fun[0.95][0](cnn_miss_m_preds[:,[2,3,4]]), m_cpi_fun[0.95][1](cnn_miss_m_preds[:,[2,3,4]])]).transpose()\n",
    "\n",
    "df_cnn_95q = pd.DataFrame(np.hstack((missM_R0_95_q, missM_delta_95_q, missM_m_95_q)),\n",
    "                         columns = [\"R0_lq\", \"R0_uq\", \"delta_lq\", \"delta_uq\", \"m_lq\", \"m_uq\"])\n",
    "df_cnn_95q.to_csv('output/missM_cnn_95q.tsv', sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569bc463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make coverage sets for numloc misspecification experiments\n",
    "\n",
    "cnn_miss_loc_preds = pd.read_table(\"../output/misspec_numloc_cnn_preds.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_loc_labels = pd.read_table(\"../output/misspec_numloc_labels.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_loc_mutips = pd.read_table(\"data_files/labels_and_preds/extant_misspec_numloc_param_values_numtips_propsamp.txt\", \n",
    "                                     header = 0).to_numpy()\n",
    "\n",
    "cnn_miss_loc_preds = np.column_stack((np.log(cnn_miss_loc_preds[:,0:3]), cnn_miss_loc_mutips[:,0], \n",
    "                                       cnn_miss_loc_mutips[:,1]/cnn_miss_loc_mutips[:,2]))\n",
    "\n",
    "i=0\n",
    "missNumLoc_R0_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_loc_preds[:,[i,3,4]], cnn_miss_loc_labels[:,i], q_fun = R0_cpi_fun)\n",
    "i=1\n",
    "missNumLoc_delta_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_loc_preds[:,[i,3,4]], cnn_miss_loc_labels[:,i], q_fun = delta_cpi_fun)\n",
    "i=2\n",
    "missNumLoc_m_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_loc_preds[:,[i,3,4]], cnn_miss_loc_labels[:,i], q_fun = m_cpi_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "31510968",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 4.201680672268908\n",
      "0.1 finished: 6.722689075630252\n",
      "0.25 finished: 23.52941176470588\n",
      "0.5 finished: 47.05882352941176\n",
      "0.75 finished: 68.90756302521008\n",
      "0.9 finished: 86.5546218487395\n",
      "0.95 finished: 92.43697478991596\n",
      "0.05 finished: 2.5210084033613445\n",
      "0.1 finished: 6.722689075630252\n",
      "0.25 finished: 16.80672268907563\n",
      "0.5 finished: 43.69747899159664\n",
      "0.75 finished: 70.58823529411765\n",
      "0.9 finished: 86.5546218487395\n",
      "0.95 finished: 93.27731092436974\n",
      "0.05 finished: 3.361344537815126\n",
      "0.1 finished: 5.042016806722689\n",
      "0.25 finished: 15.966386554621847\n",
      "0.5 finished: 34.45378151260504\n",
      "0.75 finished: 57.98319327731093\n",
      "0.9 finished: 69.74789915966386\n",
      "0.95 finished: 75.63025210084034\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3573\n"
     ]
    }
   ],
   "source": [
    "df_missNumLoc_cnn_coverage = pd.DataFrame(np.transpose(np.vstack((missNumLoc_R0_coverage, missNumLoc_delta_coverage, missNumLoc_m_coverage))), \n",
    "                                            columns = [\"R0\", \"sample_rate\", \"migration_rate\"], \n",
    "                               index = [\"5\", \"10\", \"25\", \"50\", \"75\", \"90\", \"95\"])\n",
    "df_missNumLoc_cnn_coverage.to_csv('../data_files/missNumLoc_cnn_coverage.tsv', sep = \"\\t\", index = True)\n",
    "\n",
    "# write 95% quantiles to file\n",
    "missNumLoc_R0_95_q = np.array([R0_cpi_fun[0.95][0](cnn_miss_loc_preds[:,[0,3,4]]), R0_cpi_fun[0.95][1](cnn_miss_loc_preds[:,[0,3,4]])]).transpose()\n",
    "missNumLoc_delta_95_q = np.array([delta_cpi_fun[0.95][0](cnn_miss_loc_preds[:,[1,3,4]]), delta_cpi_fun[0.95][1](cnn_miss_loc_preds[:,[1,3,4]])]).transpose()\n",
    "missNumLoc_m_95_q = np.array([m_cpi_fun[0.95][0](cnn_miss_loc_preds[:,[2,3,4]]), m_cpi_fun[0.95][1](cnn_miss_loc_preds[:,[2,3,4]])]).transpose()\n",
    "\n",
    "df_cnn_95q = pd.DataFrame(np.hstack((missNumLoc_R0_95_q, missNumLoc_delta_95_q, missNumLoc_m_95_q)),\n",
    "                         columns = [\"R0_lq\", \"R0_uq\", \"delta_lq\", \"delta_uq\", \"m_lq\", \"m_uq\"])\n",
    "df_cnn_95q.to_csv('output/missNumLoc_cnn_95q.tsv', sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "311b8c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 2.9702970297029703\n",
      "0.1 finished: 4.9504950495049505\n",
      "0.25 finished: 18.81188118811881\n",
      "0.5 finished: 31.683168316831683\n",
      "0.75 finished: 54.45544554455446\n",
      "0.9 finished: 70.29702970297029\n",
      "0.95 finished: 77.22772277227723\n",
      "0.05 finished: 3.9603960396039604\n",
      "0.1 finished: 5.9405940594059405\n",
      "0.25 finished: 16.831683168316832\n",
      "0.5 finished: 35.64356435643564\n",
      "0.75 finished: 53.46534653465347\n",
      "0.9 finished: 68.31683168316832\n",
      "0.95 finished: 77.22772277227723\n",
      "0.05 finished: 5.9405940594059405\n",
      "0.1 finished: 9.900990099009901\n",
      "0.25 finished: 21.782178217821784\n",
      "0.5 finished: 39.603960396039604\n",
      "0.75 finished: 66.33663366336634\n",
      "0.9 finished: 86.13861386138613\n",
      "0.95 finished: 91.0891089108911\n"
     ]
    }
   ],
   "source": [
    "# make coverage sets for tree misspecification experiments\n",
    "\n",
    "cnn_miss_tree_preds = pd.read_table(\"../output/misspec_tree_cnn_preds.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_tree_labels = pd.read_table(\"../output/misspec_tree_labels.tsv\", header = 0).to_numpy()\n",
    "cnn_miss_tree_mutips = pd.read_table(\"data_files/labels_and_preds/extant_misspec_tree_param_values_numtips_propsamp.txt\", \n",
    "                                     header = 0).to_numpy()\n",
    "\n",
    "cnn_miss_tree_preds = np.column_stack((np.log(cnn_miss_tree_preds[:,0:3]), cnn_miss_tree_mutips[:,0], \n",
    "                                       cnn_miss_tree_mutips[:,1]/cnn_miss_tree_mutips[:,2]))\n",
    "\n",
    "i=0\n",
    "missTree_R0_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_tree_preds[:,[i,3,4]], cnn_miss_tree_labels[:,i], q_fun = R0_cpi_fun)\n",
    "i=1\n",
    "missTree_delta_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_tree_preds[:,[i,3,4]], cnn_miss_tree_labels[:,i], q_fun = delta_cpi_fun)\n",
    "i=2\n",
    "missTree_m_coverage = uq.make_coverage_set(None, None, \n",
    "                                   cnn_miss_tree_preds[:,[i,3,4]], cnn_miss_tree_labels[:,i], q_fun = m_cpi_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ea2bdafc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 finished: 2.9702970297029703\n",
      "0.1 finished: 2.9702970297029703\n",
      "0.25 finished: 20.792079207920793\n",
      "0.5 finished: 31.683168316831683\n",
      "0.75 finished: 54.45544554455446\n",
      "0.9 finished: 72.27722772277228\n",
      "0.95 finished: 78.21782178217822\n",
      "0.05 finished: 4.9504950495049505\n",
      "0.1 finished: 5.9405940594059405\n",
      "0.25 finished: 16.831683168316832\n",
      "0.5 finished: 34.65346534653465\n",
      "0.75 finished: 53.46534653465347\n",
      "0.9 finished: 69.3069306930693\n",
      "0.95 finished: 79.20792079207921\n",
      "0.05 finished: 5.9405940594059405\n",
      "0.1 finished: 9.900990099009901\n",
      "0.25 finished: 19.801980198019802\n",
      "0.5 finished: 38.613861386138616\n",
      "0.75 finished: 67.32673267326733\n",
      "0.9 finished: 87.12871287128714\n",
      "0.95 finished: 92.07920792079209\n"
     ]
    }
   ],
   "source": [
    "df_missTree_cnn_coverage = pd.DataFrame(np.transpose(np.vstack((missTree_R0_coverage, missTree_delta_coverage, missTree_m_coverage))), \n",
    "                                            columns = [\"R0\", \"sample_rate\", \"migration_rate\"], \n",
    "                               index = [\"5\", \"10\", \"25\", \"50\", \"75\", \"90\", \"95\"])\n",
    "df_missTree_cnn_coverage.to_csv('../data_files/missTree_cnn_coverage.tsv', sep = \"\\t\", index = True)\n",
    "\n",
    "# write 95% quantiles to file\n",
    "missTree_R0_95_q = np.array([R0_cpi_fun[0.95][0](cnn_miss_tree_preds[:,[0,3,4]]), R0_cpi_fun[0.95][1](cnn_miss_tree_preds[:,[0,3,4]])]).transpose()\n",
    "missTree_delta_95_q = np.array([delta_cpi_fun[0.95][0](cnn_miss_tree_preds[:,[1,3,4]]), delta_cpi_fun[0.95][1](cnn_miss_tree_preds[:,[1,3,4]])]).transpose()\n",
    "missTree_m_95_q = np.array([m_cpi_fun[0.95][0](cnn_miss_tree_preds[:,[2,3,4]]), m_cpi_fun[0.95][1](cnn_miss_tree_preds[:,[2,3,4]])]).transpose()\n",
    "\n",
    "df_cnn_95q = pd.DataFrame(np.hstack((missTree_R0_95_q, missTree_delta_95_q, missTree_m_95_q)),\n",
    "                         columns = [\"R0_lq\", \"R0_uq\", \"delta_lq\", \"delta_uq\", \"m_lq\", \"m_uq\"])\n",
    "df_cnn_95q.to_csv('output/missTree_cnn_95q.tsv', sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92c359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdae42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
