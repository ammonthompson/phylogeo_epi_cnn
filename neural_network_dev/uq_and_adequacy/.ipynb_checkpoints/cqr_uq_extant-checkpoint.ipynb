{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c44607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import io\n",
    "from io import StringIO\n",
    "import re\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "from keras import models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as sp\n",
    "from scipy.stats import kde\n",
    "import importlib as im\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "\n",
    "# my utilities\n",
    "import cnn_utilities as cn\n",
    "import uq_utilities_2 as uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e11e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define pinball loss functions\n",
    "qq = 0.75\n",
    "def pinball_loss(y_true, y_pred, tau):\n",
    "    err = y_true - y_pred\n",
    "    return K.mean(K.maximum(tau*err, (tau-1)*err), axis=-1)\n",
    "\n",
    "def pinball_loss_lower(y_true, y_pred):\n",
    "    return pinball_loss(y_true, y_pred, tau = (1-qq)/2)\n",
    "\n",
    "def pinball_loss_upper(y_true, y_pred):\n",
    "    return pinball_loss(y_true, y_pred, tau = 1 - (1-qq)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952dd832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD trained models and normalization values\n",
    "# point est model\n",
    "point_est_model = models.load_model(\"../saved_models/train_extant_R0_sampleRate_migrationRate.hdf5\")\n",
    "\n",
    "\n",
    "# quantile models\n",
    "q95_model = models.load_model(\"trained_quantile_CNN/cqr95_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "q90_model = models.load_model(\"trained_quantile_CNN/cqr90_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "q75_model = models.load_model(\"trained_quantile_CNN/cqr75_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "q50_model = models.load_model(\"trained_quantile_CNN/cqr50_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "q25_model = models.load_model(\"trained_quantile_CNN/cqr25_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "q10_model = models.load_model(\"trained_quantile_CNN/cqr10_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "q05_model = models.load_model(\"trained_quantile_CNN/cqr05_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b94ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load normalization values\n",
    "\n",
    "mean_sd = pd.read_csv(\"trained_quantile_CNN/cqr_train_extant_normalization_label_mean_sd.csv\",\n",
    "                           index_col=0).to_numpy()\n",
    "\n",
    "train_means = mean_sd[0,:]\n",
    "train_sd = mean_sd[1,:]\n",
    "train_aux_priors_means = train_means[3:,]\n",
    "train_aux_priors_sd = train_sd[3:,]\n",
    "\n",
    "num_locs = 5\n",
    "max_tips = 502\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af05e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ checking coverage #################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537fd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# calibration data set ###\n",
    "##########################\n",
    "uq_cblv_data = pd.read_csv(\"data_files/labels_and_preds/uq_calibration_sets_0to40.cblv.csv\",\n",
    "                            header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "uq_labels = pd.read_table(\"data_files/labels_and_preds/uq_calibration_sets_0to40_labels.tsv\", header = 0).to_numpy()\n",
    "uq_normalized_labels = cn.normalize(np.log(uq_labels[:,0:3]), mean_sd[:,0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfa2bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize data order\n",
    "randomized_idx = np.random.permutation(uq_cblv_data.shape[0])\n",
    "uq_cblv_data = uq_cblv_data[randomized_idx,:]\n",
    "uq_normalized_labels = uq_normalized_labels[randomized_idx,:]\n",
    "\n",
    "# create input tensors\n",
    "uq_subsample_prop = uq_cblv_data[:,(max_tips-1) * 7]\n",
    "uq_mu = uq_cblv_data[:,(max_tips - 3) * 7]\n",
    "uq_num_tips = cn.get_num_tips(uq_cblv_data)\n",
    "\n",
    "aux_uq_cal = np.vstack((uq_mu, uq_subsample_prop, uq_num_tips,\n",
    "                          uq_labels[randomized_idx,8], uq_labels[randomized_idx,9])).transpose()\n",
    "\n",
    "norm_aux_uq_cal = cn.normalize(aux_uq_cal, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "# create input tensors\n",
    "aux_uq_treeLocation_tensor, aux_uq_prior_tensor = cn.create_data_tensors(data = uq_cblv_data, \n",
    "                                                                                    mu = norm_aux_uq_cal[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_uq_cal[:,1],\n",
    "                                                                                    num_tips = norm_aux_uq_cal[:,2],\n",
    "                                                                                    tmrca = norm_aux_uq_cal[:,3],\n",
    "                                                                                    mean_bl = norm_aux_uq_cal[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9bbdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# PREDICT R0, sample rate, migration rate\n",
    "cnn_norm_preds = {}\n",
    "cnn_norm_preds[0.05] = np.array(q05_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor])) \n",
    "cnn_norm_preds[0.10] = np.array(q10_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor])) \n",
    "cnn_norm_preds[0.25] = np.array(q25_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor])) \n",
    "cnn_norm_preds[0.50] = np.array(q50_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_norm_preds[0.75] = np.array(q75_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_norm_preds[0.90] = np.array(q90_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_norm_preds[0.95] = np.array(q95_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4ffaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# holdout a validation set for after calibration\n",
    "# split calibration prediction dat for conformal prediction interval estimation and validation\n",
    "uq_num_val = 5000\n",
    "\n",
    "cal_uq_normalized_labels = uq_normalized_labels[uq_num_val:,:]\n",
    "\n",
    "cal_norm_preds = {}\n",
    "for k in cnn_norm_preds.keys():\n",
    "    cal_norm_preds[k] = cnn_norm_preds[k][:,uq_num_val:,:]\n",
    "    \n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7382e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# CQR: Conformalization terms\n",
    "# get quantile adjustment scalars for the upper and lower quants for the three rate params\n",
    "adj_norm_cqr = {}\n",
    "for k in cal_norm_preds.keys():\n",
    "    adj_norm_cqr[k] = uq.get_CQR_constant(cal_norm_preds[k], cal_uq_normalized_labels, \n",
    "                                          inner_quantile=k, symmetric = False)\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4afc257e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'uq_utilities_2' from 'C:\\\\Users\\\\ammon_work\\\\Desktop\\\\RESEARCH_PROJECTS\\\\phylogeo_epi_cnn\\\\neural_network_dev\\\\uq_and_adequacy\\\\uq_utilities_2.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.reload(uq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3d134801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 108559, 3)\n",
      "done\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 4201\n"
     ]
    }
   ],
   "source": [
    "# function for computing all quantiles for calibration validation and \n",
    "# each experiment and populating an output dictionary\n",
    "\n",
    "def get_adj_ci(pred, adj):\n",
    "    if(len(adj.shape) > 1):\n",
    "        return np.array((pred[0] + adj[0,:], pred[1] + adj[1,:]))\n",
    "    else:\n",
    "        return np.array((pred[0] - adj, pred[1] + adj))\n",
    "\n",
    "    \n",
    "    \n",
    "def get_cqr_ci(treeloc_tensor, prior_tensor, adj_CQR_dict):\n",
    "    tm = train_means[0:3]\n",
    "    tsd = train_sd[0:3]\n",
    "    prior_bounds = np.array(([2,8],[0.0001,0.005], [0.0001,0.005]))\n",
    "\n",
    "    # PREDICT R0, sample rate, migration rate\n",
    "    preds = {}\n",
    "    preds[0.05] = np.array(q05_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    preds[0.10] = np.array(q10_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    preds[0.25] = np.array(q25_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    preds[0.50] = np.array(q50_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    preds[0.75] = np.array(q75_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    preds[0.90] = np.array(q90_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    preds[0.95] = np.array(q95_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    \n",
    "    adj_uq = {}\n",
    "    for k in preds.keys():\n",
    "        adj_uq[k] = get_adj_ci(preds[k], adj_CQR_dict[k])\n",
    "        \n",
    "    # denormalize\n",
    "    adj_lin_uq = {}\n",
    "    for k in adj_uq.keys():\n",
    "        plt.show()\n",
    "        adj_lin_uq[k] = np.exp(cn.denormalize(adj_uq[k], tm, tsd))\n",
    "        \n",
    "    # set quantiles that extend beyond the prior bounds to the boundary value\n",
    "    for i in range(prior_bounds.shape[0]):\n",
    "        for k in adj_lin_uq.keys():\n",
    "            \n",
    "            # adjust prior violating intervals to boundary value\n",
    "            too_low_idx = np.where(adj_lin_uq[k][0,:,i] < prior_bounds[i,0])\n",
    "            too_high_idx = np.where(adj_lin_uq[k][1,:,i] > prior_bounds[i,1])\n",
    "            adj_lin_uq[k][0,too_low_idx,i] = prior_bounds[i,0]\n",
    "            adj_lin_uq[k][1,too_high_idx,i] = prior_bounds[i,1]\n",
    "\n",
    "    \n",
    "    return(adj_lin_uq)\n",
    "    \n",
    "\n",
    "print(cal_norm_preds[0.05].shape)   \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388eabd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 4199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-111-39fed77f7be3>\", line 7, in <module>\n",
      "    adj_val_uq = get_cqr_ci(aux_uq_treeLocation_tensor[:uq_num_val,:,:], aux_uq_prior_tensor[:uq_num_val,:], adj_norm_cqr)\n",
      "  File \"<ipython-input-110-eb264812047a>\", line 21, in get_cqr_ci\n",
      "    preds[0.25] = np.array(q25_model.predict([treeloc_tensor, prior_tensor]))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3735, in __call__\n",
      "    [x._numpy() for x in outputs],  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3735, in <listcomp>\n",
      "    [x._numpy() for x in outputs],  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 908, in _numpy\n",
      "    return self._numpy_internal()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-111-39fed77f7be3>\", line 7, in <module>\n",
      "    adj_val_uq = get_cqr_ci(aux_uq_treeLocation_tensor[:uq_num_val,:,:], aux_uq_prior_tensor[:uq_num_val,:], adj_norm_cqr)\n",
      "  File \"<ipython-input-110-eb264812047a>\", line 21, in get_cqr_ci\n",
      "    preds[0.25] = np.array(q25_model.predict([treeloc_tensor, prior_tensor]))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3735, in __call__\n",
      "    [x._numpy() for x in outputs],  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3735, in <listcomp>\n",
      "    [x._numpy() for x in outputs],  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 908, in _numpy\n",
      "    return self._numpy_internal()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-111-39fed77f7be3>\", line 7, in <module>\n",
      "    adj_val_uq = get_cqr_ci(aux_uq_treeLocation_tensor[:uq_num_val,:,:], aux_uq_prior_tensor[:uq_num_val,:], adj_norm_cqr)\n",
      "  File \"<ipython-input-110-eb264812047a>\", line 21, in get_cqr_ci\n",
      "    preds[0.25] = np.array(q25_model.predict([treeloc_tensor, prior_tensor]))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3735, in __call__\n",
      "    [x._numpy() for x in outputs],  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3735, in <listcomp>\n",
      "    [x._numpy() for x in outputs],  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 908, in _numpy\n",
      "    return self._numpy_internal()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ammon_work\\Anaconda3\\envs\\tf-keras-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# get CNN coverage for 5000 validation datasets ##\n",
    "##################################################\n",
    "\n",
    "# get coverages and output files for CQR validation set\n",
    "uq_val_labels  =  np.exp(cn.denormalize(uq_normalized_labels[:uq_num_val,:], train_means[0:3], train_sd[0:3]))\n",
    "adj_val_uq = get_cqr_ci(aux_uq_treeLocation_tensor[:uq_num_val,:,:], aux_uq_prior_tensor[:uq_num_val,:], adj_norm_cqr)\n",
    "\n",
    "val_coverage = uq.make_cqr_coverage_set(adj_val_uq, uq_val_labels)\n",
    "\n",
    "uq.make_output_files(val_coverage, adj_val_uq, \"output/validation_CQR\")\n",
    "\n",
    "df_uq_val_labels = pd.DataFrame(uq_val_labels[:,0:3],\n",
    "                             columns = [\"R0\", \"delta\", \"m\"])\n",
    "df_uq_val_labels.to_csv(\"output/validation_CQR_labels.tsv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f30b0803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 5.68\n",
      "Quantile 0.05, parameter 1 finished: 4.84\n",
      "Quantile 0.05, parameter 2 finished: 5.76\n",
      "Quantile 0.1, parameter 0 finished: 8.52\n",
      "Quantile 0.1, parameter 1 finished: 5.7\n",
      "Quantile 0.1, parameter 2 finished: 8.08\n",
      "Quantile 0.25, parameter 0 finished: 22.42\n",
      "Quantile 0.25, parameter 1 finished: 20.22\n",
      "Quantile 0.25, parameter 2 finished: 21.86\n",
      "Quantile 0.5, parameter 0 finished: 41.22\n",
      "Quantile 0.5, parameter 1 finished: 35.34\n",
      "Quantile 0.5, parameter 2 finished: 52.46\n",
      "Quantile 0.75, parameter 0 finished: 75.62\n",
      "Quantile 0.75, parameter 1 finished: 70.52\n",
      "Quantile 0.75, parameter 2 finished: 71.12\n",
      "Quantile 0.9, parameter 0 finished: 87.66\n",
      "Quantile 0.9, parameter 1 finished: 88.34\n",
      "Quantile 0.9, parameter 2 finished: 86.68\n",
      "Quantile 0.95, parameter 0 finished: 93.88\n",
      "Quantile 0.95, parameter 1 finished: 92.94\n",
      "Quantile 0.95, parameter 2 finished: 91.56\n"
     ]
    }
   ],
   "source": [
    "# get coverages for the uncalibrated quantiles for comparison\n",
    "cnn_preds = {} \n",
    "for k,v in cnn_norm_preds.items():    \n",
    "    cnn_preds[k] = np.exp(np.array((cn.denormalize(v[0,:uq_num_val,:], train_means[0:3], train_sd[0:3]), \n",
    "                              cn.denormalize(v[1,:uq_num_val,:], train_means[0:3], train_sd[0:3]) )))\n",
    "\n",
    "uncalibrated_val_coverage = uq.make_cqr_coverage_set(cnn_preds, uq_val_labels)\n",
    "\n",
    "uq.make_output_files(uncalibrated_val_coverage, cnn_preds, \"output/uncalibrated_validation_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a79239bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Begin test ###################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1237d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_full_data = pd.read_csv(\"../data_files/extant_training_set_0to40.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0, nrows = 5000).to_numpy()\n",
    "\n",
    "tr_full_labels = pd.read_csv(\"../data_files/extant_training_set_0to40_labels.csv\",\n",
    "                    header = None, error_bad_lines = False, nrows = 5000).to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec90df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 499, 7) (5000, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_means = mean_sd[0,:]\n",
    "# train_sd = mean_sd[1,:]\n",
    "# train_aux_priors_means = train_means[3:,]\n",
    "# train_aux_priors_sd = train_sd[3:,]\n",
    "\n",
    "\n",
    "tr_num_tips = cn.get_num_tips(tr_full_data)\n",
    "tr_subsample_prop = tr_full_data[:,(max_tips-1) * 7]\n",
    "tr_mu = tr_full_data[:,(max_tips - 3) * 7]\n",
    "\n",
    "\n",
    "\n",
    "# set up auxilliary priors and normalize; tree statistics and prior known parameter values (or ranges) \n",
    "# get num_tips and normalize\n",
    "tr_aux_priors_treestats = np.vstack((tr_mu, tr_subsample_prop, tr_num_tips, \n",
    "                                  tr_full_labels[:,8], \n",
    "                                  tr_full_labels[:,9])).transpose()\n",
    "tr_norm_train_aux_priors_treestats = cn.normalize(tr_aux_priors_treestats, \n",
    "                                                 (train_aux_priors_means,\n",
    "                                                  train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# dev create data tensors\n",
    "        \n",
    "tr_full_treeLocation_tensor, tr_full_prior_tensor = cn.create_data_tensors(data = tr_full_data, \n",
    "                                                                        mu = tr_norm_train_aux_priors_treestats[:,0],\n",
    "                                                                        subsample_prop = tr_norm_train_aux_priors_treestats[:,1],\n",
    "                                                                        num_tips = tr_norm_train_aux_priors_treestats[:,2],\n",
    "                                                                        tmrca = tr_norm_train_aux_priors_treestats[:,3],\n",
    "                                                                        mean_bl = tr_norm_train_aux_priors_treestats[:,4],\n",
    "                                                                        num_locs = num_locs,\n",
    "                                                                        max_tips = max_tips,\n",
    "                                                                        cblv_contains_mu_rho = True)\n",
    "\n",
    "print(tr_full_treeLocation_tensor.shape, tr_full_prior_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3b02636",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 6.76\n",
      "Quantile 0.05, parameter 1 finished: 5.96\n",
      "Quantile 0.05, parameter 2 finished: 6.98\n",
      "Quantile 0.1, parameter 0 finished: 9.32\n",
      "Quantile 0.1, parameter 1 finished: 8.8\n",
      "Quantile 0.1, parameter 2 finished: 10.26\n",
      "Quantile 0.25, parameter 0 finished: 26.76\n",
      "Quantile 0.25, parameter 1 finished: 25.34\n",
      "Quantile 0.25, parameter 2 finished: 25.92\n",
      "Quantile 0.5, parameter 0 finished: 46.76\n",
      "Quantile 0.5, parameter 1 finished: 39.92\n",
      "Quantile 0.5, parameter 2 finished: 54.32\n",
      "Quantile 0.75, parameter 0 finished: 80.78\n",
      "Quantile 0.75, parameter 1 finished: 75.68\n",
      "Quantile 0.75, parameter 2 finished: 74.64\n",
      "Quantile 0.9, parameter 0 finished: 91.04\n",
      "Quantile 0.9, parameter 1 finished: 90.44\n",
      "Quantile 0.9, parameter 2 finished: 90.94\n",
      "Quantile 0.95, parameter 0 finished: 95.08\n",
      "Quantile 0.95, parameter 1 finished: 94.86\n",
      "Quantile 0.95, parameter 2 finished: 95.32\n"
     ]
    }
   ],
   "source": [
    "# predict quantiles and adjust with CQR. Then make files\n",
    "tr_train_cqr = get_cqr_ci(tr_full_treeLocation_tensor, tr_full_prior_tensor, adj_norm_cqr)\n",
    "tr_train_coverage = uq.make_cqr_coverage_set(tr_train_cqr, tr_full_labels[:,5:8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cnn_preds = {} \n",
    "for k,v in cnn_norm_preds.items():    \n",
    "    tr_cnn_preds[k] = np.exp(np.array((cn.denormalize(v[0,:uq_num_val,:], train_means[0:3], train_sd[0:3]), \n",
    "                              cn.denormalize(v[1,:uq_num_val,:], train_means[0:3], train_sd[0:3]) )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b56374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ end TEst ###################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92674b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#####################################\n",
    "## get coverages from experiments ###\n",
    "#####################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7ebdeb6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 6.52\n",
      "Quantile 0.05, parameter 1 finished: 2.9\n",
      "Quantile 0.05, parameter 2 finished: 6.52\n",
      "Quantile 0.1, parameter 0 finished: 7.25\n",
      "Quantile 0.1, parameter 1 finished: 11.59\n",
      "Quantile 0.1, parameter 2 finished: 11.59\n",
      "Quantile 0.25, parameter 0 finished: 31.16\n",
      "Quantile 0.25, parameter 1 finished: 28.26\n",
      "Quantile 0.25, parameter 2 finished: 31.88\n",
      "Quantile 0.5, parameter 0 finished: 55.07\n",
      "Quantile 0.5, parameter 1 finished: 47.83\n",
      "Quantile 0.5, parameter 2 finished: 52.17\n",
      "Quantile 0.75, parameter 0 finished: 82.61\n",
      "Quantile 0.75, parameter 1 finished: 77.54\n",
      "Quantile 0.75, parameter 2 finished: 81.16\n",
      "Quantile 0.9, parameter 0 finished: 94.93\n",
      "Quantile 0.9, parameter 1 finished: 95.65\n",
      "Quantile 0.9, parameter 2 finished: 89.13\n",
      "Quantile 0.95, parameter 0 finished: 94.93\n",
      "Quantile 0.95, parameter 1 finished: 96.38\n",
      "Quantile 0.95, parameter 2 finished: 94.2\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_phylocomp.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_phylocomp_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "phylocomp_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((phylocomp_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "phylocomp_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor, adj_norm_cqr)\n",
    "phylocomp_coverage = uq.make_cqr_coverage_set(phylocomp_cqr, extant_labels[:,5:8])\n",
    "uq.make_output_files(phylocomp_coverage, phylocomp_cqr, \"output/phylocomp_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93f0ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 1.08\n",
      "Quantile 0.05, parameter 1 finished: 2.15\n",
      "Quantile 0.05, parameter 2 finished: 1.08\n",
      "Quantile 0.1, parameter 0 finished: 4.3\n",
      "Quantile 0.1, parameter 1 finished: 5.38\n",
      "Quantile 0.1, parameter 2 finished: 6.45\n",
      "Quantile 0.25, parameter 0 finished: 5.38\n",
      "Quantile 0.25, parameter 1 finished: 22.58\n",
      "Quantile 0.25, parameter 2 finished: 16.13\n",
      "Quantile 0.5, parameter 0 finished: 8.6\n",
      "Quantile 0.5, parameter 1 finished: 46.24\n",
      "Quantile 0.5, parameter 2 finished: 25.81\n",
      "Quantile 0.75, parameter 0 finished: 16.13\n",
      "Quantile 0.75, parameter 1 finished: 76.34\n",
      "Quantile 0.75, parameter 2 finished: 49.46\n",
      "Quantile 0.9, parameter 0 finished: 32.26\n",
      "Quantile 0.9, parameter 1 finished: 80.65\n",
      "Quantile 0.9, parameter 2 finished: 52.69\n",
      "Quantile 0.95, parameter 0 finished: 44.09\n",
      "Quantile 0.95, parameter 1 finished: 90.32\n",
      "Quantile 0.95, parameter 2 finished: 74.19\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_R0.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_R0_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missR0_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missR0_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missR0_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor, adj_norm_cqr)\n",
    "missR0_coverage = uq.make_cqr_coverage_set(missR0_cqr, extant_labels[:,5:8])\n",
    "uq.make_output_files(missR0_coverage, missR0_cqr, \"output/missR0_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49e1bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 4.24\n",
      "Quantile 0.05, parameter 1 finished: 1.69\n",
      "Quantile 0.05, parameter 2 finished: 3.39\n",
      "Quantile 0.1, parameter 0 finished: 9.32\n",
      "Quantile 0.1, parameter 1 finished: 3.39\n",
      "Quantile 0.1, parameter 2 finished: 7.63\n",
      "Quantile 0.25, parameter 0 finished: 19.49\n",
      "Quantile 0.25, parameter 1 finished: 14.41\n",
      "Quantile 0.25, parameter 2 finished: 14.41\n",
      "Quantile 0.5, parameter 0 finished: 45.76\n",
      "Quantile 0.5, parameter 1 finished: 28.81\n",
      "Quantile 0.5, parameter 2 finished: 33.9\n",
      "Quantile 0.75, parameter 0 finished: 73.73\n",
      "Quantile 0.75, parameter 1 finished: 41.53\n",
      "Quantile 0.75, parameter 2 finished: 55.93\n",
      "Quantile 0.9, parameter 0 finished: 88.98\n",
      "Quantile 0.9, parameter 1 finished: 71.19\n",
      "Quantile 0.9, parameter 2 finished: 65.25\n",
      "Quantile 0.95, parameter 0 finished: 94.92\n",
      "Quantile 0.95, parameter 1 finished: 71.19\n",
      "Quantile 0.95, parameter 2 finished: 72.03\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_delta.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_delta_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missDelta_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missDelta_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missDelta_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor, adj_norm_cqr)\n",
    "missDelta_coverage = uq.make_cqr_coverage_set(missDelta_cqr, extant_labels[:,5:8])\n",
    "uq.make_output_files(missDelta_coverage, missDelta_cqr, \"output/missDelta_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e73b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 4.44\n",
      "Quantile 0.05, parameter 1 finished: 4.44\n",
      "Quantile 0.05, parameter 2 finished: 4.44\n",
      "Quantile 0.1, parameter 0 finished: 10.0\n",
      "Quantile 0.1, parameter 1 finished: 10.0\n",
      "Quantile 0.1, parameter 2 finished: 6.67\n",
      "Quantile 0.25, parameter 0 finished: 17.78\n",
      "Quantile 0.25, parameter 1 finished: 28.89\n",
      "Quantile 0.25, parameter 2 finished: 16.67\n",
      "Quantile 0.5, parameter 0 finished: 51.11\n",
      "Quantile 0.5, parameter 1 finished: 47.78\n",
      "Quantile 0.5, parameter 2 finished: 25.56\n",
      "Quantile 0.75, parameter 0 finished: 70.0\n",
      "Quantile 0.75, parameter 1 finished: 76.67\n",
      "Quantile 0.75, parameter 2 finished: 50.0\n",
      "Quantile 0.9, parameter 0 finished: 84.44\n",
      "Quantile 0.9, parameter 1 finished: 87.78\n",
      "Quantile 0.9, parameter 2 finished: 68.89\n",
      "Quantile 0.95, parameter 0 finished: 93.33\n",
      "Quantile 0.95, parameter 1 finished: 94.44\n",
      "Quantile 0.95, parameter 2 finished: 73.33\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_m.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_m_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missM_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missM_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missM_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor, adj_norm_cqr)\n",
    "missM_coverage = uq.make_cqr_coverage_set(missM_cqr, extant_labels[:,5:8])\n",
    "uq.make_output_files(missM_coverage, missM_cqr, \"output/missM_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc904bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 5.04\n",
      "Quantile 0.05, parameter 1 finished: 5.88\n",
      "Quantile 0.05, parameter 2 finished: 2.52\n",
      "Quantile 0.1, parameter 0 finished: 9.24\n",
      "Quantile 0.1, parameter 1 finished: 5.04\n",
      "Quantile 0.1, parameter 2 finished: 4.2\n",
      "Quantile 0.25, parameter 0 finished: 22.69\n",
      "Quantile 0.25, parameter 1 finished: 28.57\n",
      "Quantile 0.25, parameter 2 finished: 15.97\n",
      "Quantile 0.5, parameter 0 finished: 44.54\n",
      "Quantile 0.5, parameter 1 finished: 40.34\n",
      "Quantile 0.5, parameter 2 finished: 33.61\n",
      "Quantile 0.75, parameter 0 finished: 69.75\n",
      "Quantile 0.75, parameter 1 finished: 72.27\n",
      "Quantile 0.75, parameter 2 finished: 57.14\n",
      "Quantile 0.9, parameter 0 finished: 89.08\n",
      "Quantile 0.9, parameter 1 finished: 89.92\n",
      "Quantile 0.9, parameter 2 finished: 74.79\n",
      "Quantile 0.95, parameter 0 finished: 93.28\n",
      "Quantile 0.95, parameter 1 finished: 95.8\n",
      "Quantile 0.95, parameter 2 finished: 81.51\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_numloc.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_numloc_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missNumLoc_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missNumLoc_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missNumLoc_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor, adj_norm_cqr)\n",
    "missNumLoc_coverage = uq.make_cqr_coverage_set(missNumLoc_cqr, extant_labels[:,5:8])\n",
    "uq.make_output_files(missNumLoc_coverage, missNumLoc_cqr, \"output/missNumLoc_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac92c359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 2.97\n",
      "Quantile 0.05, parameter 1 finished: 2.97\n",
      "Quantile 0.05, parameter 2 finished: 2.97\n",
      "Quantile 0.1, parameter 0 finished: 4.95\n",
      "Quantile 0.1, parameter 1 finished: 2.97\n",
      "Quantile 0.1, parameter 2 finished: 16.83\n",
      "Quantile 0.25, parameter 0 finished: 14.85\n",
      "Quantile 0.25, parameter 1 finished: 18.81\n",
      "Quantile 0.25, parameter 2 finished: 22.77\n",
      "Quantile 0.5, parameter 0 finished: 39.6\n",
      "Quantile 0.5, parameter 1 finished: 36.63\n",
      "Quantile 0.5, parameter 2 finished: 50.5\n",
      "Quantile 0.75, parameter 0 finished: 58.42\n",
      "Quantile 0.75, parameter 1 finished: 56.44\n",
      "Quantile 0.75, parameter 2 finished: 70.3\n",
      "Quantile 0.9, parameter 0 finished: 72.28\n",
      "Quantile 0.9, parameter 1 finished: 73.27\n",
      "Quantile 0.9, parameter 2 finished: 86.14\n",
      "Quantile 0.95, parameter 0 finished: 79.21\n",
      "Quantile 0.95, parameter 1 finished: 71.29\n",
      "Quantile 0.95, parameter 2 finished: 87.13\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_tree.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_tree_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missTree_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missTree_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missTree_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor, adj_norm_cqr)\n",
    "missTree_coverage = uq.make_cqr_coverage_set(missTree_cqr, extant_labels[:,5:8])\n",
    "uq.make_output_files(missTree_coverage, missTree_cqr, \"output/missTree_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdae42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d2012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39373c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
