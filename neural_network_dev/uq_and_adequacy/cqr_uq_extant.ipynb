{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c44607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import io\n",
    "from io import StringIO\n",
    "import re\n",
    "import sys\n",
    "from contextlib import redirect_stdout\n",
    "from keras import models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as sp\n",
    "from scipy.stats import kde\n",
    "import importlib as im\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "\n",
    "# my utilities\n",
    "import cnn_utilities as cn\n",
    "import uq_utilities_2 as uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88cd2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3721\n"
     ]
    }
   ],
   "source": [
    "## define pinball loss functions\n",
    "qq = 0.75\n",
    "def pinball_loss(y_true, y_pred, tau):\n",
    "    err = y_true - y_pred\n",
    "    return K.mean(K.maximum(tau*err, (tau-1)*err), axis=-1)\n",
    "\n",
    "def pinball_loss_lower(y_true, y_pred):\n",
    "    return pinball_loss(y_true, y_pred, tau = (1-qq)/2)\n",
    "\n",
    "def pinball_loss_upper(y_true, y_pred):\n",
    "    return pinball_loss(y_true, y_pred, tau = 1 - (1-qq)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "462eaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD trained models and normalization values\n",
    "# point est model\n",
    "point_est_model = models.load_model(\"../saved_models/train_extant_R0_sampleRate_migrationRate.hdf5\")\n",
    "\n",
    "mean_sd = pd.read_csv(\"trained_quantile_CNN/cqr_train_extant_normalization_label_mean_sd.csv\",\n",
    "                           index_col=0).to_numpy()\n",
    "\n",
    "\n",
    "# quantile models\n",
    "q95_model = models.load_model(\"trained_quantile_CNN/cqr95_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "q90_model = models.load_model(\"trained_quantile_CNN/cqr90_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "q75_model = models.load_model(\"trained_quantile_CNN/cqr75_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "q50_model = models.load_model(\"trained_quantile_CNN/cqr50_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "q25_model = models.load_model(\"trained_quantile_CNN/cqr25_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "q10_model = models.load_model(\"trained_quantile_CNN/cqr10_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "q05_model = models.load_model(\"trained_quantile_CNN/cqr05_train_extant_R0_sampleRate_migrationRate.hdf5\",\n",
    "                              custom_objects = {'pinball_loss_lower': pinball_loss_lower, \n",
    "                                                'pinball_loss_upper': pinball_loss_upper})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b94ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model and normalization values\n",
    "train_means = mean_sd[0,:]\n",
    "train_sd = mean_sd[1,:]\n",
    "train_aux_priors_means = train_means[3:,]\n",
    "train_aux_priors_sd = train_sd[3:,]\n",
    "\n",
    "num_locs = 5\n",
    "max_tips = 502\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af05e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ checking coverage #################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "537fd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data set\n",
    "uq_cblv_data = pd.read_csv(\"data_files/labels_and_preds/uq_calibration_sets_0to40.cblv.csv\",\n",
    "                            header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "uq_labels = pd.read_table(\"data_files/labels_and_preds/uq_calibration_sets_0to40_labels.tsv\", header = 0).to_numpy()\n",
    "uq_normalized_labels = cn.normalize(np.log(uq_labels[:,0:3]), mean_sd[:,0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "07aaa8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize data order\n",
    "randomized_idx = np.random.permutation(uq_cblv_data.shape[0])\n",
    "uq_cblv_data = uq_cblv_data[randomized_idx,:]\n",
    "uq_normalized_labels = uq_normalized_labels[randomized_idx,:]\n",
    "\n",
    "# create input tensors\n",
    "uq_subsample_prop = uq_cblv_data[:,(max_tips-1) * 7]\n",
    "uq_mu = uq_cblv_data[:,(max_tips - 3) * 7]\n",
    "uq_num_tips = cn.get_num_tips(uq_cblv_data)\n",
    "\n",
    "aux_uq_cal = np.vstack((uq_mu, uq_subsample_prop, uq_num_tips,\n",
    "                          uq_labels[randomized_idx,8], uq_labels[randomized_idx,9])).transpose()\n",
    "\n",
    "norm_aux_uq_cal = cn.normalize(aux_uq_cal, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "# create input tensors\n",
    "aux_uq_treeLocation_tensor, aux_uq_prior_tensor = cn.create_data_tensors(data = uq_cblv_data, \n",
    "                                                                                    mu = norm_aux_uq_cal[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_uq_cal[:,1],\n",
    "                                                                                    num_tips = norm_aux_uq_cal[:,2],\n",
    "                                                                                    tmrca = norm_aux_uq_cal[:,3],\n",
    "                                                                                    mean_bl = norm_aux_uq_cal[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "bf9bbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT R0, sample rate, migration rate\n",
    "cnn_uq95_normalized_preds = np.array(q95_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_uq90_normalized_preds = np.array(q90_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_uq75_normalized_preds = np.array(q75_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_uq50_normalized_preds = np.array(q50_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_uq25_normalized_preds = np.array(q25_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_uq10_normalized_preds = np.array(q10_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "cnn_uq05_normalized_preds = np.array(q05_model.predict([aux_uq_treeLocation_tensor, aux_uq_prior_tensor]))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "8270f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# holdout a validation set for after calibration\n",
    "# split calibration prediction dat for conformal prediction interval estimation and validation\n",
    "uq_num_val = 5000\n",
    "\n",
    "cal_uq_normalized_labels = uq_normalized_labels[uq_num_val:,:]\n",
    "cal_uq95_normalized_preds = cnn_uq95_normalized_preds[:,uq_num_val:,:]\n",
    "cal_uq90_normalized_preds = cnn_uq90_normalized_preds[:,uq_num_val:,:]\n",
    "cal_uq75_normalized_preds = cnn_uq75_normalized_preds[:,uq_num_val:,:]\n",
    "cal_uq50_normalized_preds = cnn_uq50_normalized_preds[:,uq_num_val:,:]\n",
    "cal_uq25_normalized_preds = cnn_uq25_normalized_preds[:,uq_num_val:,:]\n",
    "cal_uq10_normalized_preds = cnn_uq10_normalized_preds[:,uq_num_val:,:]\n",
    "cal_uq05_normalized_preds = cnn_uq05_normalized_preds[:,uq_num_val:,:]\n",
    "\n",
    "uq_val_normalized_labels = uq_normalized_labels[:uq_num_val,:]\n",
    "val_uq95_normalized_preds = cnn_uq95_normalized_preds[:,:uq_num_val,:]\n",
    "val_uq90_normalized_preds = cnn_uq90_normalized_preds[:,:uq_num_val,:]\n",
    "val_uq75_normalized_preds = cnn_uq75_normalized_preds[:,:uq_num_val,:]\n",
    "val_uq50_normalized_preds = cnn_uq50_normalized_preds[:,:uq_num_val,:]\n",
    "val_uq25_normalized_preds = cnn_uq25_normalized_preds[:,:uq_num_val,:]\n",
    "val_uq10_normalized_preds = cnn_uq10_normalized_preds[:,:uq_num_val,:]\n",
    "val_uq05_normalized_preds = cnn_uq05_normalized_preds[:,:uq_num_val,:]\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "f069fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conformally adjust pinball estimates of ci\n",
    "def get_adj_ci(pred, adj):\n",
    "    if(len(adj.shape) > 1):\n",
    "        return np.array((pred[0] + adj[0,:], pred[1] + adj[1,:]))\n",
    "    else:\n",
    "        return np.array((pred[0] - adj, pred[1] + adj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "79a6291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# get quantile adjustment scalars for the three rate params\n",
    "adj_normalized_cqr95 = uq.get_CQR_constant(cal_uq95_normalized_preds, cal_uq_normalized_labels, inner_quantile=0.95, symmetric = False)\n",
    "adj_normalized_cqr90 = uq.get_CQR_constant(cal_uq90_normalized_preds, cal_uq_normalized_labels, inner_quantile=0.90, symmetric = False)\n",
    "adj_normalized_cqr75 = uq.get_CQR_constant(cal_uq75_normalized_preds, cal_uq_normalized_labels, inner_quantile=0.75, symmetric = False)\n",
    "adj_normalized_cqr50 = uq.get_CQR_constant(cal_uq50_normalized_preds, cal_uq_normalized_labels, inner_quantile=0.50, symmetric = False)\n",
    "adj_normalized_cqr25 = uq.get_CQR_constant(cal_uq25_normalized_preds, cal_uq_normalized_labels, inner_quantile=0.25, symmetric = False)\n",
    "adj_normalized_cqr10 = uq.get_CQR_constant(cal_uq10_normalized_preds, cal_uq_normalized_labels, inner_quantile=0.10, symmetric = False)\n",
    "adj_normalized_cqr05 = uq.get_CQR_constant(cal_uq05_normalized_preds, cal_uq_normalized_labels, inner_quantile=0.05, symmetric = False)\n",
    "\n",
    "# get validation quantiles\n",
    "adj_normalized_val_uq = {}\n",
    "adj_normalized_val_uq[0.05] = get_adj_ci(val_uq05_normalized_preds, adj_normalized_cqr05)\n",
    "adj_normalized_val_uq[0.10] = get_adj_ci(val_uq10_normalized_preds, adj_normalized_cqr10)\n",
    "adj_normalized_val_uq[0.25] = get_adj_ci(val_uq25_normalized_preds, adj_normalized_cqr25)\n",
    "adj_normalized_val_uq[0.50] = get_adj_ci(val_uq50_normalized_preds, adj_normalized_cqr50)\n",
    "adj_normalized_val_uq[0.75] = get_adj_ci(val_uq75_normalized_preds, adj_normalized_cqr75)\n",
    "adj_normalized_val_uq[0.90] = get_adj_ci(val_uq90_normalized_preds, adj_normalized_cqr90)\n",
    "adj_normalized_val_uq[0.95] = get_adj_ci(val_uq95_normalized_preds, adj_normalized_cqr95)\n",
    "\n",
    "# denormalize\n",
    "adj_val_uq = {}\n",
    "for i in adj_normalized_val_uq.keys():\n",
    "    adj_val_uq[i] = np.exp(cn.denormalize(adj_normalized_val_uq[i], train_means[0:3], train_sd[0:3]))\n",
    "\n",
    "uq_val_labels  =  np.exp(cn.denormalize(uq_val_normalized_labels, train_means[0:3], train_sd[0:3]))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "958a0133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 4.98\n",
      "Quantile 0.05, parameter 1 finished: 4.68\n",
      "Quantile 0.05, parameter 2 finished: 5.16\n",
      "Quantile 0.1, parameter 0 finished: 9.98\n",
      "Quantile 0.1, parameter 1 finished: 9.56\n",
      "Quantile 0.1, parameter 2 finished: 9.9\n",
      "Quantile 0.25, parameter 0 finished: 23.54\n",
      "Quantile 0.25, parameter 1 finished: 24.44\n",
      "Quantile 0.25, parameter 2 finished: 25.08\n",
      "Quantile 0.5, parameter 0 finished: 50.02\n",
      "Quantile 0.5, parameter 1 finished: 49.14\n",
      "Quantile 0.5, parameter 2 finished: 49.98\n",
      "Quantile 0.75, parameter 0 finished: 75.04\n",
      "Quantile 0.75, parameter 1 finished: 74.98\n",
      "Quantile 0.75, parameter 2 finished: 75.66\n",
      "Quantile 0.9, parameter 0 finished: 89.82\n",
      "Quantile 0.9, parameter 1 finished: 89.82\n",
      "Quantile 0.9, parameter 2 finished: 89.52\n",
      "Quantile 0.95, parameter 0 finished: 95.3\n",
      "Quantile 0.95, parameter 1 finished: 95.22\n",
      "Quantile 0.95, parameter 2 finished: 94.72\n"
     ]
    }
   ],
   "source": [
    "# get coverages and output files\n",
    "val_coverage = uq.make_cqr_coverage_set(adj_val_uq, uq_val_labels[:,0:3])\n",
    "make_output_files(val_coverage, adj_val_uq, \"output/validation_CQR\")\n",
    "\n",
    "df_uq_val_labels = pd.DataFrame(uq_val_labels[:,0:3],\n",
    "                             columns = [\"R0\", \"delta\", \"m\"])\n",
    "df_uq_val_labels.to_csv(\"output/validation_CQR_labels.tsv\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "id": "bb51ff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 1127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#####################################\n",
    "## get coverages from experimente ###\n",
    "#####################################\n",
    "\n",
    "prior_bounds[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "90cb62cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# function for computing all quantiles for each experiment and populating an output dictionary\n",
    "\n",
    "# uniform prior boundaries. Use for fair comparison against Bayesian method\n",
    "prior_bounds = np.array([[2, 8],[0.0001, 0.005], [0.0001, 0.005]])\n",
    "\n",
    "def get_adj_ci(pred, adj):\n",
    "    if(len(adj.shape) > 1):\n",
    "        return np.array((pred[0] + adj[0,:], pred[1] + adj[1,:]))\n",
    "    else:\n",
    "        return np.array((pred[0] - adj, pred[1] + adj))\n",
    "\n",
    "    \n",
    "def get_cqr_ci(treeloc_tensor, prior_tensor):\n",
    "    tm = train_means[0:3]\n",
    "    tsd = train_sd[0:3]\n",
    "    \n",
    "    # PREDICT R0, sample rate, migration rate\n",
    "    uq95_preds = np.array(q95_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    uq90_preds = np.array(q90_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    uq75_preds = np.array(q75_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    uq50_preds = np.array(q50_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    uq25_preds = np.array(q25_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    uq10_preds = np.array(q10_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    uq05_preds = np.array(q05_model.predict([treeloc_tensor, prior_tensor]))\n",
    "    \n",
    "    adj_uq = {}\n",
    "    adj_uq[0.05] = get_adj_ci(uq05_preds, adj_normalized_cqr05)\n",
    "    adj_uq[0.10] = get_adj_ci(uq10_preds, adj_normalized_cqr10)\n",
    "    adj_uq[0.25] = get_adj_ci(uq25_preds, adj_normalized_cqr25)\n",
    "    adj_uq[0.50] = get_adj_ci(uq50_preds, adj_normalized_cqr50)\n",
    "    adj_uq[0.75] = get_adj_ci(uq75_preds, adj_normalized_cqr75)\n",
    "    adj_uq[0.90] = get_adj_ci(uq90_preds, adj_normalized_cqr90)\n",
    "    adj_uq[0.95] = get_adj_ci(uq95_preds, adj_normalized_cqr95)\n",
    "        \n",
    "    # denormalize\n",
    "    adj_lin_uq = {}\n",
    "    for i in adj_uq.keys():\n",
    "        plt.show()\n",
    "        adj_lin_uq[i] = np.exp(cn.denormalize(adj_uq[i], tm, tsd))\n",
    "        \n",
    "    # resolve absurd intervals (upper_q < lower_q) by flipping them\n",
    "    # set quantiles that extend beyond the prior bounds to the boundary value\n",
    "    for i in range(prior_bounds.shape[0]):\n",
    "        for k in adj_lin_uq.keys():\n",
    "            # flip backwards intervals\n",
    "            backwards_idx = np.where(adj_lin_uq[k][0,:,i] > adj_lin_uq[k][1,:,i])\n",
    "            low_vals = adj_lin_uq[k][0,backwards_idx,i]\n",
    "            adj_lin_uq[k][0,backwards_idx,i] = adj_lin_uq[k][1,backwards_idx,i]\n",
    "            adj_lin_uq[k][1,backwards_idx,i] = low_vals\n",
    "            \n",
    "            # adjust prior violating intervals to boundary value\n",
    "            too_low_idx = np.where(adj_lin_uq[k][0,:,i] < prior_bounds[i,0])\n",
    "            too_high_idx = np.where(adj_lin_uq[k][1,:,i] > prior_bounds[i,1])\n",
    "            adj_lin_uq[k][0,too_low_idx,i] = prior_bounds[i,0]\n",
    "            adj_lin_uq[k][1,too_high_idx,i] = prior_bounds[i,1]\n",
    "\n",
    "    \n",
    "    return(adj_lin_uq)\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "id": "902585ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 5.8\n",
      "Quantile 0.05, parameter 1 finished: 4.35\n",
      "Quantile 0.05, parameter 2 finished: 4.35\n",
      "Quantile 0.1, parameter 0 finished: 10.14\n",
      "Quantile 0.1, parameter 1 finished: 9.42\n",
      "Quantile 0.1, parameter 2 finished: 9.42\n",
      "Quantile 0.25, parameter 0 finished: 25.36\n",
      "Quantile 0.25, parameter 1 finished: 25.36\n",
      "Quantile 0.25, parameter 2 finished: 24.64\n",
      "Quantile 0.5, parameter 0 finished: 52.17\n",
      "Quantile 0.5, parameter 1 finished: 55.07\n",
      "Quantile 0.5, parameter 2 finished: 51.45\n",
      "Quantile 0.75, parameter 0 finished: 81.16\n",
      "Quantile 0.75, parameter 1 finished: 81.16\n",
      "Quantile 0.75, parameter 2 finished: 77.54\n",
      "Quantile 0.9, parameter 0 finished: 92.75\n",
      "Quantile 0.9, parameter 1 finished: 88.41\n",
      "Quantile 0.9, parameter 2 finished: 89.13\n",
      "Quantile 0.95, parameter 0 finished: 97.83\n",
      "Quantile 0.95, parameter 1 finished: 97.1\n",
      "Quantile 0.95, parameter 2 finished: 94.93\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# get CNN coverage ##\n",
    "########################################\n",
    "\n",
    "extant_data = pd.read_csv(\"../data_files/extant_phylocomp.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_phylocomp_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "phylocomp_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((phylocomp_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "phylocomp_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor)\n",
    "phylocomp_coverage = uq.make_cqr_coverage_set(phylocomp_cqr, extant_labels[:,5:8])\n",
    "make_output_files(phylocomp_coverage, phylocomp_cqr, \"output/phylocomp_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "id": "fb3ec9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 2.15\n",
      "Quantile 0.05, parameter 1 finished: 4.3\n",
      "Quantile 0.05, parameter 2 finished: 7.53\n",
      "Quantile 0.1, parameter 0 finished: 1.08\n",
      "Quantile 0.1, parameter 1 finished: 6.45\n",
      "Quantile 0.1, parameter 2 finished: 6.45\n",
      "Quantile 0.25, parameter 0 finished: 3.23\n",
      "Quantile 0.25, parameter 1 finished: 23.66\n",
      "Quantile 0.25, parameter 2 finished: 16.13\n",
      "Quantile 0.5, parameter 0 finished: 13.98\n",
      "Quantile 0.5, parameter 1 finished: 45.16\n",
      "Quantile 0.5, parameter 2 finished: 26.88\n",
      "Quantile 0.75, parameter 0 finished: 18.28\n",
      "Quantile 0.75, parameter 1 finished: 67.74\n",
      "Quantile 0.75, parameter 2 finished: 43.01\n",
      "Quantile 0.9, parameter 0 finished: 34.41\n",
      "Quantile 0.9, parameter 1 finished: 81.72\n",
      "Quantile 0.9, parameter 2 finished: 55.91\n",
      "Quantile 0.95, parameter 0 finished: 40.86\n",
      "Quantile 0.95, parameter 1 finished: 91.4\n",
      "Quantile 0.95, parameter 2 finished: 63.44\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_R0.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_R0_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missR0_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missR0_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missR0_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor)\n",
    "missR0_coverage = uq.make_cqr_coverage_set(missR0_cqr, extant_labels[:,5:8])\n",
    "make_output_files(missR0_coverage, missR0_cqr, \"output/missR0_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "830d840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 6.78\n",
      "Quantile 0.05, parameter 1 finished: 2.54\n",
      "Quantile 0.05, parameter 2 finished: 2.54\n",
      "Quantile 0.1, parameter 0 finished: 10.17\n",
      "Quantile 0.1, parameter 1 finished: 5.08\n",
      "Quantile 0.1, parameter 2 finished: 6.78\n",
      "Quantile 0.25, parameter 0 finished: 28.81\n",
      "Quantile 0.25, parameter 1 finished: 11.86\n",
      "Quantile 0.25, parameter 2 finished: 11.86\n",
      "Quantile 0.5, parameter 0 finished: 45.76\n",
      "Quantile 0.5, parameter 1 finished: 24.58\n",
      "Quantile 0.5, parameter 2 finished: 34.75\n",
      "Quantile 0.75, parameter 0 finished: 73.73\n",
      "Quantile 0.75, parameter 1 finished: 45.76\n",
      "Quantile 0.75, parameter 2 finished: 44.07\n",
      "Quantile 0.9, parameter 0 finished: 89.83\n",
      "Quantile 0.9, parameter 1 finished: 68.64\n",
      "Quantile 0.9, parameter 2 finished: 65.25\n",
      "Quantile 0.95, parameter 0 finished: 92.37\n",
      "Quantile 0.95, parameter 1 finished: 80.51\n",
      "Quantile 0.95, parameter 2 finished: 77.12\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_delta.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_delta_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missDelta_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missDelta_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missDelta_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor)\n",
    "missDelta_coverage = uq.make_cqr_coverage_set(missDelta_cqr, extant_labels[:,5:8])\n",
    "make_output_files(missDelta_coverage, missDelta_cqr, \"output/missDelta_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "id": "34b8a4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 3.33\n",
      "Quantile 0.05, parameter 1 finished: 7.78\n",
      "Quantile 0.05, parameter 2 finished: 2.22\n",
      "Quantile 0.1, parameter 0 finished: 13.33\n",
      "Quantile 0.1, parameter 1 finished: 11.11\n",
      "Quantile 0.1, parameter 2 finished: 2.22\n",
      "Quantile 0.25, parameter 0 finished: 25.56\n",
      "Quantile 0.25, parameter 1 finished: 22.22\n",
      "Quantile 0.25, parameter 2 finished: 12.22\n",
      "Quantile 0.5, parameter 0 finished: 48.89\n",
      "Quantile 0.5, parameter 1 finished: 43.33\n",
      "Quantile 0.5, parameter 2 finished: 26.67\n",
      "Quantile 0.75, parameter 0 finished: 71.11\n",
      "Quantile 0.75, parameter 1 finished: 66.67\n",
      "Quantile 0.75, parameter 2 finished: 47.78\n",
      "Quantile 0.9, parameter 0 finished: 91.11\n",
      "Quantile 0.9, parameter 1 finished: 90.0\n",
      "Quantile 0.9, parameter 2 finished: 70.0\n",
      "Quantile 0.95, parameter 0 finished: 97.78\n",
      "Quantile 0.95, parameter 1 finished: 93.33\n",
      "Quantile 0.95, parameter 2 finished: 76.67\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_m.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_m_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missM_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missM_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missM_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor)\n",
    "missM_coverage = uq.make_cqr_coverage_set(missM_cqr, extant_labels[:,5:8])\n",
    "make_output_files(missM_coverage, missM_cqr, \"output/missM_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "id": "2a44cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 10.08\n",
      "Quantile 0.05, parameter 1 finished: 5.04\n",
      "Quantile 0.05, parameter 2 finished: 3.36\n",
      "Quantile 0.1, parameter 0 finished: 11.76\n",
      "Quantile 0.1, parameter 1 finished: 12.61\n",
      "Quantile 0.1, parameter 2 finished: 5.88\n",
      "Quantile 0.25, parameter 0 finished: 19.33\n",
      "Quantile 0.25, parameter 1 finished: 21.01\n",
      "Quantile 0.25, parameter 2 finished: 17.65\n",
      "Quantile 0.5, parameter 0 finished: 47.9\n",
      "Quantile 0.5, parameter 1 finished: 43.7\n",
      "Quantile 0.5, parameter 2 finished: 43.7\n",
      "Quantile 0.75, parameter 0 finished: 71.43\n",
      "Quantile 0.75, parameter 1 finished: 74.79\n",
      "Quantile 0.75, parameter 2 finished: 57.14\n",
      "Quantile 0.9, parameter 0 finished: 86.55\n",
      "Quantile 0.9, parameter 1 finished: 93.28\n",
      "Quantile 0.9, parameter 2 finished: 72.27\n",
      "Quantile 0.95, parameter 0 finished: 91.6\n",
      "Quantile 0.95, parameter 1 finished: 94.12\n",
      "Quantile 0.95, parameter 2 finished: 83.19\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_numloc.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_numloc_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missNumLoc_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missNumLoc_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missNumLoc_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor)\n",
    "missNumLoc_coverage = uq.make_cqr_coverage_set(missNumLoc_cqr, extant_labels[:,5:8])\n",
    "make_output_files(missNumLoc_coverage, missNumLoc_cqr, \"output/missNumLoc_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "ac92c359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05, parameter 0 finished: 5.94\n",
      "Quantile 0.05, parameter 1 finished: 2.97\n",
      "Quantile 0.05, parameter 2 finished: 2.97\n",
      "Quantile 0.1, parameter 0 finished: 7.92\n",
      "Quantile 0.1, parameter 1 finished: 9.9\n",
      "Quantile 0.1, parameter 2 finished: 7.92\n",
      "Quantile 0.25, parameter 0 finished: 19.8\n",
      "Quantile 0.25, parameter 1 finished: 17.82\n",
      "Quantile 0.25, parameter 2 finished: 20.79\n",
      "Quantile 0.5, parameter 0 finished: 31.68\n",
      "Quantile 0.5, parameter 1 finished: 41.58\n",
      "Quantile 0.5, parameter 2 finished: 43.56\n",
      "Quantile 0.75, parameter 0 finished: 54.46\n",
      "Quantile 0.75, parameter 1 finished: 58.42\n",
      "Quantile 0.75, parameter 2 finished: 69.31\n",
      "Quantile 0.9, parameter 0 finished: 79.21\n",
      "Quantile 0.9, parameter 1 finished: 68.32\n",
      "Quantile 0.9, parameter 2 finished: 85.15\n",
      "Quantile 0.95, parameter 0 finished: 80.2\n",
      "Quantile 0.95, parameter 1 finished: 73.27\n",
      "Quantile 0.95, parameter 2 finished: 90.1\n"
     ]
    }
   ],
   "source": [
    "extant_data = pd.read_csv(\"../data_files/extant_misspec_tree.cblv.csv\", \n",
    "                   header =None, error_bad_lines = False, index_col = 0).to_numpy()\n",
    "\n",
    "extant_labels = pd.read_csv(\"../data_files/extant_misspec_tree_labels.csv\",\n",
    "                    header = None, error_bad_lines = False).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compute and gather auxilliary prior data\n",
    "extant_subsample_prop = extant_data[:,(max_tips-1) * 7]\n",
    "missTree_mu = extant_data[:,(max_tips - 3) * 7]\n",
    "extant_num_tips = cn.get_num_tips(extant_data)\n",
    "\n",
    "aux_phylocomp = np.vstack((missTree_mu, extant_subsample_prop, extant_num_tips,\n",
    "                          extant_labels[:,8], extant_labels[:,9])).transpose()\n",
    "\n",
    "norm_aux_phylocomp = cn.normalize(aux_phylocomp, (train_aux_priors_means, train_aux_priors_sd))\n",
    "\n",
    "\n",
    "# create input tensors\n",
    "extant_treeLocation_tensor, extant_prior_tensor = cn.create_data_tensors(data = extant_data, \n",
    "                                                                                    mu = norm_aux_phylocomp[:,0],\n",
    "                                                                                    subsample_prop = norm_aux_phylocomp[:,1],\n",
    "                                                                                    num_tips = norm_aux_phylocomp[:,2],\n",
    "                                                                                    tmrca = norm_aux_phylocomp[:,3],\n",
    "                                                                                    mean_bl = norm_aux_phylocomp[:,4],\n",
    "                                                                                    num_locs = num_locs,\n",
    "                                                                                    max_tips = max_tips,\n",
    "                                                                                    cblv_contains_mu_rho = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predict quantiles and adjust with CQR. Then make files\n",
    "missTree_cqr = get_cqr_ci(extant_treeLocation_tensor, extant_prior_tensor)\n",
    "missTree_coverage = uq.make_cqr_coverage_set(missTree_cqr, extant_labels[:,5:8])\n",
    "make_output_files(missTree_coverage, missTree_cqr, \"output/missTree_CQR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdae42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c66de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
