loadPlugin("TensorPhylo", "/home/athompson/software/tensorphylo/build/installer/lib")

sim_num = 117
run = 1
num_gen = 100000
thin = 10
symetric=true

# true param treated as known for all inference methods
S_0 = 1000000
recovery_rate = 0.01804
subsampling_p = 1
num_locations = 5

# true param values for computing error
true_delta = [0.00254,0.00254,0.00254,0.00254,0.00254]
true_R0 = [6.09927,6.09927,6.09927,6.09927,6.09927]
true_migration = 0.002947348
true_root = 4

# process data
data_file = "true_phylogeo_sim23_rep0.location_tree.nexus"

out_file = "test_underprior_sim23.log"


tree = readTrees(data_file)[1]
taxa = tree.taxa()

data = readDiscreteCharacterData(data_file)
k    = data.getStateDescriptions().size()


# set parameters
age <- tree.rootAge() + tree.branchLength(tree.nnodes())
moves = VectorMoves()


# make the tensors
#mu_param ~ dnUniform(0.5 * recovery_rate, 1.5 * recovery_rate)
#moves.append(mvSlide(mu_param))
#mu := rep(mu_param, k)
mu <- rep(recovery_rate, k)


# sampling rate param
delta_param ~ dnUniform(0.0001,0.005)
moves.append(mvSlide(delta_param))
delta := rep(delta_param, k)

# beta_M is the beta param in MASTER which = beta/N. 
# Note in dI/dt = beta/N * S * I - gamma * I
# beta/N = beta_M
# R_0 = beta_M * S_0 / gamma = beta/N * S_0 / gamma = beta_M * S_0 / mu
# therefore lambda = beta_M * S_0 = mu * R_0
# if destructive sampling, lambda = (delta + mu) * R_0

R_0_param ~ dnUniform(2,8)
R_0_param.setValue(4)
moves.append(mvSlide(R_0_param))
R_0 := rep(R_0_param , k)
lambda := (delta + mu) * R_0_param
beta_MASTER := lambda / S_0

# delta, R0 joint move
moves.append(mvUpDownSlide())
deltaR0_joint_updown_idx = moves.size()
moves[deltaR0_joint_updown_idx].addVariable(delta_param, true)
moves[deltaR0_joint_updown_idx].addVariable(R_0_param, false)

moves.append(mvUpDownSlide())
deltaR0_joint_downup_idx = moves.size()
moves[deltaR0_joint_downup_idx].addVariable(delta_param, false)
moves[deltaR0_joint_downup_idx].addVariable(R_0_param, true)



# mass-event parameters
rho <- 0.00000000000000000001



# anagenetic events
#for(i in 1:choose(k,2)){
#	m[i] ~ dnExponential(1)
#	moves.append(mvScale(m[i]))
#	m[i].setValue(0.01)
#}
#eta := fnFreeSymmetricRateMatrix(m, rescaled = FALSE)

pairwise_migration_rate ~ dnUniform(0.0001,0.005)
moves.append(mvSlide(pairwise_migration_rate))

for(i in 1:k){
       for(j in 1:k){
               if( i == j){
                       m[i][j] <- 0

               }else{
			if(symetric){
				if(j > i){
					m[i][j] := pairwise_migration_rate
				}else{
					m[i][j] := m[j][i]
				}
			}else{
				m[i][j] := pairwise_migration_rate
			}
               }
       }
}
eta := fnFreeK(m, rescaled = FALSE)


root_freq <- simplex(rep(1, k))
#root_freq ~ dnDirichlet(rep(1,k))
#moves.append(mvBetaSimplex(root_freq))
#moves.append(mvElementSwapSimplex(root_freq))
#zz_shifted_root_state ~ dnCategorical(root_freq)
#moves.append(mvRandomIntegerWalk(zz_shifted_root_state, weight = 5))
#root_state := zz_shifted_root_state - 1



# condition
#condition <- "sampled"
condition <- "time"
#condition <- "survival"

# distribution object. also called dnGLHBDSP()
psi ~ dnGeneralizedLineageHeterogeneousBirthDeathProcess(
                originAge      = age,
				pi			 = root_freq,
                lambda       = lambda,
				eta          = eta,
				mu           = mu,
                delta        = delta,
				rho          = rho,
				condition    = condition,
                taxa         = taxa,
				nStates		 = k,
				nProc		 = 1
)
psi.clamp(tree)
psi.clampCharData(data)


# model
my_model = model(psi)

# monitors
monitors = VectorMonitors()
monitors.append(mnScreen(printgen=100))
monitors.append(mnModel(printgen=thin, filename=out_file))
#monitors.append(mnModel(printgen=thin, filename="output/sim" + sim_num + "_run" + run + "_tp.log"))


# analysis
my_mcmc = mcmc(my_model, monitors, moves)
my_mcmc.burnin(num_gen * 0.1, 100, underPrior = TRUE)
my_mcmc.run(num_gen, underPrior = TRUE)
q()








