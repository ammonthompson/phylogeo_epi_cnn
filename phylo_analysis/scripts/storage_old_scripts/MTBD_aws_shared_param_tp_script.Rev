loadPlugin("TensorPhylo", "/home/athompson/software/tensorphylo/build/installer/lib")

# sim_num = 46

num_gen = 15000
thin = 1
symetric=true

# true param treated as known for all inference methods
S_0 = 5000000
recovery_rate = .03705
subsampling_p = 1
num_locations = 5

# true param values for computing error
true_delta = [.00012,.00012,.00012,.00012,.00012]
true_R0 = [7.81265,10.80413,7.09847,10.59095,5.97659]
true_migration = .00090
true_root = 4

# process data
data_file = "tree_files/mtbd_true_sim46_rep0.location_tree.nexus"

out_file = "output/mtbd_true_sim46.log"

tree = readTrees(data_file)[1]
taxa = tree.taxa()

data = readDiscreteCharacterData(data_file)
k    = data.getStateDescriptions().size()


# set parameters
age <- tree.rootAge() + tree.branchLength(tree.nnodes())
moves = VectorMoves()


# make the tensors
#mu_param ~ dnUniform(0.5 * recovery_rate, 1.5 * recovery_rate)
#moves.append(mvSlide(mu_param))
#mu := rep(mu_param, k)
mu <- rep(recovery_rate, k)


# sampling rate param
delta_param ~ dnUniform(0.0001, 0.005)
#moves.append(mvSlide(delta_param))
moves.append(mvScale(delta_param, weight = 1.25))
delta := rep(delta_param, k)
subsample_delta := delta * subsampling_p

# beta_M is the beta param in MASTER which = beta/N. 
# Note in dI/dt = beta/N * S * I - gamma * I
# beta/N = beta_M
# R_0 = beta_M * S_0 / gamma = beta/N * S_0 / gamma = beta_M * S_0 / mu
# therefore lambda = beta_M * S_0 = mu * R_0
# if destructive sampling, lambda = (delta + mu) * R_0

max_dif = 8
R_0_midpoint ~ dnUniform(0.9 + max_dif/2, 15 - max_dif/2)
moves.append(mvSlide(R_0_midpoint))
moves.append(mvUpDownSlide(weight = 1.25))
deltaR0_joint_updown_idx = moves.size()
moves[deltaR0_joint_updown_idx].addVariable(delta_param, true)
for(i in 1:k){
	R_0[i] ~ dnUniform(R_0_midpoint - max_dif/2, R_0_midpoint + max_dif/2)
	moves.append(mvSlide(R_0[i]))
	moves[deltaR0_joint_updown_idx].addVariable(R_0[i], false)	
#	lambda[i] := (delta + mu) * R_0[i]
}
lambda := abs((delta + mu) * R_0)

# mass-event parameters
rho <- 0.0000000000000000001



# anagenetic events
#for(i in 1:choose(k,2)){
#	m[i] ~ dnExponential(1)
#	moves.append(mvScale(m[i]))
#	m[i].setValue(0.01)
#}
#eta := fnFreeSymmetricRateMatrix(m, rescaled = FALSE)

pairwise_migration_rate ~ dnUniform(0.0001, 0.005)
#moves.append(mvSlide(pairwise_migration_rate, weight = 0.5))
moves.append(mvScale(pairwise_migration_rate, weight = 0.25))

for(i in 1:k){
       for(j in 1:k){
               if( i == j){
                       m[i][j] <- 0

               }else{
			if(symetric){
				if(j > i){
					m[i][j] := pairwise_migration_rate
				}else{
					m[i][j] := m[j][i]
				}
			}else{
				m[i][j] := pairwise_migration_rate
			}
               }
       }
}
eta := fnFreeK(m, rescaled = FALSE)


root_freq <- Simplex(rep(1, k))

# condition
#condition <- "sampled"
#condition <- "time"
#condition <- "survival"
condition <- "tree"

# distribution object. also called dnGLHBDSP()
psi ~ dnGeneralizedLineageHeterogeneousBirthDeathProcess(
                originAge      = age,
		pi           = root_freq,
                lambda       = lambda,
		eta          = eta,
		mu           = mu,
                delta        = subsample_delta,
		rho          = rho,
		condition    = condition,
                taxa         = taxa,
		nStates	     = k,
		zeroIndex    = TRUE,
		nProc	     = 1
)
psi.clamp(tree)
psi.clampCharData(data)


# model
my_model = model(psi)

# monitors
monitors = VectorMonitors()
monitors.append(mnScreen(printgen=100))
monitors.append(mnModel(printgen=thin, filename=out_file))
monitors.append(mnJointConditionalAncestralState(tree, psi, filename = out_file + ".ancStates", 
		type = "Standard", printgen= 10 * thin, withStartStates = true)) 


# analysis
my_mcmc = mcmc(my_model, monitors, moves)
my_mcmc.burnin(num_gen * 0.1, 100)
my_mcmc.run(num_gen)
q()








